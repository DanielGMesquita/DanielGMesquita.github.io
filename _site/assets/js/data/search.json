[
  
  {
    "title": "Estrutura de dados - introdução e tipos abstratos",
    "url": "/posts/data-structures-intro/",
    "categories": "Programação, Estrutura de dados",
    "tags": "programação, algoritmos, estrutura de dados, tipos abstratos de dados",
    "date": "2024-12-22 02:31:00 -0300",
    





    
    "snippet": "Eu decidi dar um passo atrás (enquanto continuo andando pra frente, parece até uma dança) nos meus estudos e colocar alguns itens básicos de computação nos meus estudos pra poder suprir algumas lac...",
    "content": "Eu decidi dar um passo atrás (enquanto continuo andando pra frente, parece até uma dança) nos meus estudos e colocar alguns itens básicos de computação nos meus estudos pra poder suprir algumas lacunas técnicas que tenho. As 3 principais frentes para este plano de fundamentos são: sistemas operacionais, redes e estrutura de dados.Normalmente trago códigos em Java pra ilustrar as coisas que estou explicando, mas considerando que estou falando de bases, pode ser necessário trazer outras linguagens que eu não tenho familiariade e vou ter que saber lidar, por exemplo C.Então, quem quiser acompanhar, só seguir aqui. Eu vou fazer postagens para me ajudar a fixar os conhecimentos e documentar meus estudos. Como eu sei que ninguém muito experiente vai consultar isto aqui, vou tentar ser o mais didático possível.Vale ressaltar, que apesar de eu escrever em PT-BR, todos os códigos são em inglês porque é o padrão que encontramos por aí.Então, contexto dado. Vamos ao que interessa. Hoje vou introduzir sobre estrutura de dados e falar de tipos abstratos de dados com alguns exemplos em Java e C.Conceitos baseExistem 3 terminologias básicas que todo programador lida mesmo se não souber a fundo seus conceitos:AlgoritmoUm algoritmo é uma sequência de ações em uma linguagem de programação buscando solucionar um problema. É o padrão de comportamento associado aos elementos funcionais ativos de um processamento e deve ter um conjunto finito de ações. Recebe um conjunto de valores como entrada e produz um conjunto de valores como saída.Estrutura de dadosDão suporte à descrição dos elementos funcionais passivos, complementando o algoritmo. Juntos eles compõem o programa a ser executado pelo computador.Uma estrutura de dados precisa considerar os algoritmos a ela associados. Assim como, escolher o algoritmo depende muitas vezes da estrutura de dados a ser utilizada.As estruturas de dados são comumente aplicadas a (não somente a) kernel (vou explicar sobre isso futuramente) de sistemas operacionais, compiladores e interpretadores, editores de texto e estruturas de bancos de dados.ProgramaJunta um com o outro, de maneira básica: estruturar dados e construir algoritmo. Essa é a base de um programa.É a formulação concreta (utilizando uma linguagem de programação) de um procedimento abstrato que atua sobre um modelo de dados também abstrato.Tipos abstratos de dadosAbstração no nosso campo de estudos é focar em aspectos essenciais de um contexto, simplificando problemas complexos. Quando usamos interfaces para algo mais complicado que acontece nos bastidores.Na programação, a abstração serve pra “esconder” a implementação de algo, fornecendo apenas o que interessa para quem está usando.Aqui um exemplo clássico é o carro. Você não precisa saber como funciona o motor a nível detalhado, como é a combustão da gasolina, como funciona o sistema elétrico, para o motorista dirigir só é necessário saber como funcionam as partes que ele interage.Alguns exemplos de abstração em programação:  Métodos estáticos: se você quiser calcular a área de um retângulo, recebendo como parâmetros da função a largura e a altura, ela precisa só das dimensões e devolve a área, você não precisa toda vez refletir sobre a fórmula largura * altura pra isso, a função “esconde” esse detalhe.    public class Main {  // Método estático que abstrai o calculo da área do retângulo  public static int calculateRectangleArea(int width, int height) {      return width * height;  }  public static void main(String[] args) {      // Usando o método      int area = calculateRectangleArea(5, 10);      System.out.println(\"The area of the rectangle is: \" + area); // Output: 50  }}            Classes e objetos: a programação orientada a objetos usa muitas abstrações nos programas, por exemplo, o nosso carro. Em ve de se preocupar com os detalhes técnicos do veículo, você pode criar uma classe com as informações que importam, como ligar(), desligar() e acelerar(). Quem for usar, não precisa saber como o motor é iniciado, apenas chama carro.ligar().```java// Classe que abstrai as funcionalidades do carroclass Car {  private String model;  private boolean isOn;    // Construtor para inicializar a classe  public Car(String model) {      this.model = model;      this.isOn = false;  }    // Liga o carro  public void turnOn() {      this.isOn = true;      System.out.println(“The “ + model + “ is now on.”);  }    // Acelera  public void accelerate() {      if (isOn) {          System.out.println(“The “ + model + “ is accelerating!”);      } else {          System.out.println(“You need to turn on the car first!”);      }  }}  public class Main {    public static void main(String[] args) {        // Cria o objeto “Car” e interage com ele        Car myCar = new Car(“Fusca”);        myCar.turnOn();        myCar.accelerate();    }}- Bibliotecas e APIs externas: quando você utiliza estes no seu programa, você só lida com funções prontas, não se preocupando como essas funções foram escritas e o seu processamento, a abstração oculta toda sua complexidade.```javapublic class Main {    public static void main(String[] args) {        // Using the sqrt method from the Math class to calculate the square root        double squareRoot = Math.sqrt(25);        System.out.println(\"The square root of 25 is: \" + squareRoot); // Output: 5.0    }}Como isso bem claro, podemos concluir que quando lidamos com um tipo abstrato de dados, nos concentramos em aspectos essenciais do tipo de dado (suas operações) e nos abstraímos da sua implementação. O usuário só enxerga a interface, quem se preocupa com a implementação é o programador.Implementação de tipos abstratos de dadosEm liguagens orientadas a objetos, como Java, costumamos utilizara para isso classes e interfaces. Já nas estruturadas, como C, definimos os tipos juntamente com a implementação das funções.Uma boa prática de programação neste caso é não acessar o dado diretamente, sempre fazendo isso através das funções.Uma boa técnica é implementar os tipos abstratos de dados em arquivos separados do programa principal.Em Java, como mostrei anteriormente, criamos a classe que abstrai o objeto e a classe que utiliza como se estivessem no mesmo arquivo, mas no mundo real, isso não ocorre.Em C, é a mesma ideia. Um arquivo para as declarações e outro com a implementação das declarações. Basicamente, utilizamos assim:  nome_tad.h: as declarações;  nome_tad.c: as implementações.E aí o programa que for utilizar vai ter usar no cabeçalho:#include &lt;stdio.h&gt;#include \"nome_tad.h\"No exemplo abaixo eu criei um programa simples em C para calcular média de gols e assitências por jogos de um jogador de futebol qualquer.  player.h (as declarações relacionadas ao “Player”):```cstruct Player {  int games;  int goals;  int assists;};void create(struct Player *p);void setPlayerStats(struct Player *p, int goals, int assists, int games);- player.c (as implementações relacionadas ao \"Player\"):```c#include \"player.h\"void create(struct Player *p){    p-&gt;games = 0;    p-&gt;goals = 0;    p-&gt;assists = 0;}void setPlayerStats(struct Player *p, int goals, int assists, int games){    p-&gt;games = games;    p-&gt;goals = goals;    p-&gt;assists = assists;}  player_evaluator.c (programa que vai fazer os cálculos utilizar as funções relacionadas ao “Player”):```c#include #include \"player.h\"int main(int argc, char *argv[]) {    int games, goals, assists;    struct Player p;    create(&amp;p);printf(\"Type number of goals...\");scanf(\"%d\", &amp;goals);printf(\"Type number of assists...\");scanf(\"%d\", &amp;assists);printf(\"Type number of games...\");scanf(\"%d\", &amp;games);setPlayerStats(&amp;p, goals, assists, games);printf(\"Assists per game: %.2f\\n\", (double)p.assists/p.games);printf(\"Goals per game: %.2f\\n\", (double)p.goals/p.games);printf(\"\\n\\nEnd of application\\n\\n\");return 0; } ``` Em C, uma estrutura (struct) é uma coleção de campos que podem ser referenciados pelo mesmo nome, perimitindo que as informações relacionadas mantenham-se juntas.A declaração de uma estrutura define um tipo de dado, informando ao computador quantos bytes a serem reservados serão necessários para uma variável que venha a ser declarada desse tipo. Organiza dados complexos de maneira legível e ajuda a modelar objetos ou entidades no programa.E o *p é o ponteiro. Uma variável que armazena o endereço de memória de outra variável. Em vez de guardar o valor diretamente, ele guarda a localização onde o valor está armazenado, assim você pode acessar e modificar variáveis por referência, fazer alocação dinâmica de memória e evita duplicação de dados quando passados para funções.E o operador -&gt; utilizamos para acessar campos de uma struct via ponteiro.Motivações para uso de tipos abstratos de dados  Reutilização: com detalhes da implementação abstraídas, pode-se utilizar uma funcionalidade em vários casos;  Manutenção: mudanças na implementação não afetam o código fonte;  Correção e testes: o código pode ser testado em diferentes contextos, diminuindo possibilidade de erros.Acho que esses conceitos foram um bom pontapé de reforço dos estudos de estruturas de dados. Agora com o conceito de abstração mais afinado, dá pra abordar as estruturas mais comuns. No próximo post sobre o assunto talvez eu aborde pilha e fila, se não ficar muito extenso para trazer os dois.Abraço!"
  },
  
  {
    "title": "Coisas que podem ajudar um iniciante a se destacar",
    "url": "/posts/three-tips-for-beginners/",
    "categories": "Carreira, Programação",
    "tags": "carreira, programação, juninho",
    "date": "2024-11-05 07:31:00 -0300",
    





    
    "snippet": "Tem três coisas pouco discutidas nos cursos voltados a iniciantes na programação: testes, documentação e comunicação.Essas coisas geralmente são negligenciadas por quem tá começando, principalmente...",
    "content": "Tem três coisas pouco discutidas nos cursos voltados a iniciantes na programação: testes, documentação e comunicação.Essas coisas geralmente são negligenciadas por quem tá começando, principalmente quem tá sem orientação.Aí quando se depara com a necessidade de se ter esses conhecimentos e habilidades em um contexto profissional, acha que é coisa de outro mundo.Eu sei porque já cometi esse erro. Saía escrevendo código, não documentava nada nem testava nada e ficava um caos depois.E não tem pra que deixar pra depois o que você não vai fazer nunca.Uma boa documentação facilita muito o compartilhamento de conhecimento sobre uma aplicação, além de ajudar na implementação, depuração e manutenção, pois inclui todos os detalhes necessários para o correto funcionamento do código. Pra documentação eu uso bastante Javadoc e o próprio Swagger, não tem muito mistério pra usar. Outra também muito útil pra quem usar o Spring, é o Spring Rest Docs.  JavaDoc: Ferramenta utilizada para gerar documentação a partir do código fonte Java. Ele adiciona comentários no código que explicam a funcionalidade de métodos, classes e pacotes, e pode ser exportado para um documento HTML. Geralmente nas IDEs tem as ferramentas de geração desse HTML pra você visualizar. Exemplo de uso:/** * Implementation of the {@link AuthenticationService} interface that provides * methods for authenticating users and managing JWT tokens. */@Servicepublic class AuthenticationServiceImpl implements AuthenticationService {  @Autowired  private UserRepository repository;  /**   * Loads a user by their username.   *   * @param login the username of the user to load   * @return the details of the user   * @throws UsernameNotFoundException if the user is not found   */  @Override  public UserDetails loadUserByUsername(String login) throws UsernameNotFoundException {    return repository.findByUsername(login);  }  /**   * Generates a JWT token for the given authentication request.   *   * @param authRequest the authentication request containing user credentials   * @return a JWT token as a string   */  @Override  public String getToken(AuthRequest authRequest) {    User user = repository.findByUsername(authRequest.getUsername());    return generateToken(user);  }  /**   * Generates a JWT token for the specified user.   *   * @param user the user for whom the token is generated   * @return a JWT token as a string   * @throws RuntimeException if token creation fails   */  public String generateToken(User user) {    try {      Algorithm algorithm = Algorithm.HMAC256(\"my-secret\");      return JWT.create()              .withIssuer(\"blog-api\")              .withSubject(user.getUsername())              .withExpiresAt(getExpirationDate())              .sign(algorithm);    } catch (JWTCreationException exception) {      throw new RuntimeException(\"Fail to generate token: \" + exception.getMessage());    }  }  /**   * Validates a JWT token and returns the subject (username) if the token is valid.   *   * @param token the JWT token to validate   * @return the subject (username) if the token is valid, or an empty string if not   */  @Override  public String validateJwt(String token) {    try {      Algorithm algorithm = Algorithm.HMAC256(\"my-secret\");      return JWT.require(algorithm).withIssuer(\"blog-api\").build().verify(token).getSubject();    } catch (JWTVerificationException e) {      return \"\";    }  }  /**   * Calculates the expiration date of the JWT token.   *   * @return the expiration date as an {@link Instant}   */  private Instant getExpirationDate() {    return LocalDateTime.now().plusHours(8).toInstant(ZoneOffset.of(\"-03:00\"));  }}  Swagger (OpenAPI): Uma especificação que documenta APIs RESTful de forma interativa. Ele permite a descrição detalhada de endpoints, parâmetros, respostas e exemplos, facilitando a integração e testes de APIs. No Swagger é recomendável utilizar as anotações @Operation, @ApiResponses, e @Parameter nos seus controladores para melhorar a documentação. No caso do Maven, você tem que adicionar a dependência no pom.xml. Por exemplo:&lt;dependency&gt;    &lt;groupId&gt;org.springdoc&lt;/groupId&gt;    &lt;artifactId&gt;springdoc-openapi-starter-webmvc-ui&lt;/artifactId&gt;    &lt;version&gt;2.5.0&lt;/version&gt;&lt;/dependency&gt;@RestController@RequestMapping(path = \"/address\")public class AddressController {  @Autowired  private AddressService service;  @Operation(summary = \"Save a new address\", description = \"Saves a new address to the database\")  @ApiResponses(value = {          @ApiResponse(responseCode = \"200\", description = \"Address saved successfully\"),          @ApiResponse(responseCode = \"400\", description = \"Invalid address details provided\")  })  @PostMapping(\"/save\")  private @ResponseBody Address save(@RequestBody Address address) {    return service.save(address);  }  @Operation(summary = \"Get all addresses\", description = \"Retrieves a list of all addresses\")  @ApiResponses(value = {          @ApiResponse(responseCode = \"200\", description = \"Successfully retrieved the addresses\")  })  @GetMapping(path = \"/getAll\")  private @ResponseBody List&lt;Address&gt; getAllAddresses() {    return service.getAll();  }  @Operation(summary = \"Get an address\", description = \"Retrieves an address by its ID\")  @ApiResponses(value = {          @ApiResponse(responseCode = \"200\", description = \"Address retrieved successfully\"),          @ApiResponse(responseCode = \"404\", description = \"Address not found\")  })  @GetMapping(path = \"/get\")  private @ResponseBody Optional&lt;Address&gt; getAddress(@RequestParam final Long id) {    return service.get(id);  }  @Operation(summary = \"Update an address\", description = \"Updates the details of an existing address\")  @ApiResponses(value = {          @ApiResponse(responseCode = \"200\", description = \"Address updated successfully\"),          @ApiResponse(responseCode = \"404\", description = \"Address not found\"),          @ApiResponse(responseCode = \"400\", description = \"Invalid address details provided\")  })  @PutMapping(path = \"/update\")  private @ResponseBody Address updateAddress(          @RequestParam final Long id, @RequestBody Address address) {    return service.update(id, address);  }  @Operation(summary = \"Delete an address\", description = \"Deletes an address by its ID\")  @ApiResponses(value = {          @ApiResponse(responseCode = \"204\", description = \"Address deleted successfully\"),          @ApiResponse(responseCode = \"404\", description = \"Address not found\")  })  @DeleteMapping(path = \"/delete\")  private ResponseEntity&lt;?&gt; delete(@RequestParam final Long id) {    service.delete(id);    return ResponseEntity.noContent().build();  }}Como você pode ver na imagem abaixo, é possível testar inclusive as chamadas aos endpoints, tendo acesso aos exemplos de entradas e saídas de cada um.  Spring Rest Docs: Integrado ao ecossistema Spring, esta ferramenta gera documentação legível e interativa a partir de testes escritos, exportando a documentação para HTML ou outros formatos.O negócio do JavaDoc que pode incomodar algumas pessoas é o fato de deixar o código muito populado por comentários, mas se você não se importar com isso, é uma boa. Agora se você quiser algo externo ao seu código, o Swagger pode ser uma boa saída.Pra testes, você tem que estudar as ferramentas de teste de cada linguagem. Mas o importante é lembrar que o teste não serve só pra validar o que você acredita, tem que testar de fato as entradas mais absurdas possíveis e tentar cobrir todo tipo de treta. Para começo, os testes unitários servem como um belo ponto de partida.Testes unitários verificam partes individuais do código para descobrir se funcionam como esperadas. O objetivo é garantir que cada “unidade” do código funcione corretamente isoladamente, sem dependências externas, como bancos de dados ou APIs. Os principais pontos importantes em fazer testes unitários para mim são:  Identificação precoce de erros, algo que reduz muito custo e tempo de correção;  Facilita a refatoração do código, dá mais confiança porque com os testes, sabemos que as mudanças não vão quebrar o código e se quebrar, o teste pode identificar isso;  Teste é documentação viva e ativa, mostrando como as funções devem se comportar;  Quando você faz testes, você acaba se preocupando em produzir um código mais testável e modular, o que acaba ajudando a aplicar boas práticas de design de código.No Java eu costumo utilizar o JUnit, que é a biblioteca de testes unitários mais popular. Também utilizo o Mockito, que é uma biblioteca de mocking que permite criar objetos simulados para testar as interações entre diferentes partes do código. Facilita os testes de partes que têm dependências externas. Exemplo de uma classe com testes unitários:class CategoryServiceTest {  @Mock private CategoryRepository categoryRepository;  @InjectMocks private CategoryService categoryService;  private List&lt;Category&gt; categories;  private final Category foodCategory = TestMocks.foodCategory;  private final Category healthCategory = TestMocks.healthCategory;  @BeforeEach  void setUp() {    MockitoAnnotations.openMocks(this);    this.categories = Arrays.asList(this.foodCategory, this.healthCategory);  }  @Test  void testFindAll() {    when(this.categoryRepository.findAll()).thenReturn(this.categories);    List&lt;Category&gt; result = this.categoryService.findAll();    assertEquals(this.categories, result);    verify(this.categoryRepository, times(1)).findAll();  }  @Test  void testFindById() {    when(this.categoryRepository.findById(1))        .thenReturn(java.util.Optional.ofNullable(this.foodCategory));    Category result = this.categoryService.findById(1);    assertEquals(this.foodCategory, result);    verify(this.categoryRepository, times(1)).findById(1);  }  @Test  void testSave() {    when(this.categoryRepository.save(this.foodCategory)).thenReturn(this.foodCategory);    Category result = this.categoryService.save(this.foodCategory);    assertEquals(this.foodCategory, result);    verify(this.categoryRepository, times(1)).save(this.foodCategory);  }  @Test  void testUpdate() {    when(this.categoryRepository.findById(1))        .thenReturn(java.util.Optional.ofNullable(this.foodCategory));    assert this.foodCategory != null;    when(this.categoryRepository.save(this.foodCategory)).thenReturn(this.foodCategory);    Category result = this.categoryService.update(1, this.foodCategory);    assertEquals(this.foodCategory, result);    verify(this.categoryRepository, times(1)).findById(1);    verify(this.categoryRepository, times(1)).save(this.foodCategory);  }  @Test  void testDeleteCategory() {    when(this.categoryRepository.findById(1))        .thenReturn(java.util.Optional.ofNullable(this.foodCategory));    assert this.foodCategory != null;    this.categoryService.deleteCategory(1);    verify(this.categoryRepository, times(1)).delete(this.foodCategory);  }}Para caso de testar a comunicação com serviços externos, seriam os testes de integração. Mas isso é para outro papo, pois implica um pouco mais de complexidade. Um dia pretendo fazer uma série no blog sobre testes.E para me dar suporte tanto na parte de documentação quanto em testes eu sempre uso a ajuda de uma IA generativa. Na documentação ajuda muito a mapear o código para criar os comentários necessários sem que você tenha que fazer tudo na mão. E para testes eu utilizo muito para debug e criação de cenários, pois às vezes eu deixo passar alguma possibilidade de erro ou problemas que possam surgir.E quanto a comunicação, eu sinto que isso para alguns desenvolvedores, principalmente quem tá começando é uma grande barreira. Ainda se vive muito aquele estereótipo do “cara de TI”, que fica fechado no escuro sem falar com ninguém só no computador. Mas isso só atrasa o desenvolvimento de qualquer um.Nosso trabalho como desenvolvedor não é só escrever o código, mas gerar valor através das soluções que desenvolvemos. E para isso, precisamos conversar com clientes, pares, líderes e todo mundo que faz parte da cadeia. Importante saber passar informação e fazer as perguntas certas, e também vender o seu trabalho bem. Não adianta achar que os resultados vão falar por si só.Acredito que o fato de ter essa softskill de comunicação bem afiada devido a mais de uma década que passei no comercial me ajudou muito a evoluir mais rápido pois consegui me relacionar bem com as pessoas certas, tive desenvoltura a lidar com clientes e pessoas de todos os níveis hierárquicos e saber conquistar meu espaço além da parte técnica.Espero que este post seja útil, fazia tempo que eu queria falar desses assuntos aqui mas me faltava tempo.Abraço!"
  },
  
  {
    "title": "Conectando bancos de dados locais - Parte VII",
    "url": "/posts/database-local-connection-pt-VII/",
    "categories": "Programação, Banco de dados, Docker",
    "tags": "programação, postegres, banco de dados, sql, docker, container",
    "date": "2024-09-29 23:00:00 -0300",
    





    
    "snippet": "No post anterior, falamos do docker compose com o MongoDB e uma aplicação Spring Boot. Hoje vou finalizar esta série (amém!) com a configuração do PostgreSQL.Configurações necessáriasVou pular a co...",
    "content": "No post anterior, falamos do docker compose com o MongoDB e uma aplicação Spring Boot. Hoje vou finalizar esta série (amém!) com a configuração do PostgreSQL.Configurações necessáriasVou pular a configuração do Dockerfile porque pouco muda, só o nome da aplicação no target.Agora vou para o docker-compose.yml, o próprio pom.xml da aplicação e o application.properties.docker-compose.yml:version: '3.9'services:  postgres_application:    container_name: postgres_application    image: postgres    volumes:      - postgres_data:/var/lib/postgresql/data    environment:      POSTGRES_DB: orderdb      POSTGRES_USER: postgres      POSTGRES_PASSWORD: admin    ports:      - \"5432:5432\"  delivery_management_api:    build: .    ports:      - \"8080:8080\"    depends_on:      - postgres_application    environment:      - SPRING_DATASOURCE_URL=jdbc:postgresql://postgres_application:5432/orderdb      - SPRING_DATASOURCE_USERNAME=postgres      - SPRING_DATASOURCE_PASSWORD=adminvolumes:  postgres_data:networks:  app-network:  Versão: Especifica a versão da sintaxe do Docker Compose que você está utilizando. A versão 3.9 é uma das versões mais recentes, oferecendo suporte a muitos recursos, como redes e volumes.  Services: Esta seção define os contêineres que serão executados. Cada contêiner é uma instância de um serviço.Serviço postgres_application:      image: Especifica a imagem do Docker a ser utilizada.        ports: Mapeia as portas do contêiner para as portas da máquina host. “5432:5432” significa que a porta 5432 do contêiner (padrão do postgres) será acessível na porta 5432 do host. Isso permite que você acesse o postgres de fora do contêiner, por exemplo, utilizando um cliente postgres.        volumes: Mapeia um volume do Docker, o que permite a persistência de dados. postgres_data:/var/lib/postgresql/data indica que o volume chamado postegres_data será utilizado para armazenar os dados do MongoDB no diretório /var/lib/postgresql/data dentro do container. Isso significa que, mesmo que o container seja destruído, os dados persistem no volume.        environment: define as configurações de acesso ao banco de dados com usuário e senha e o nome do banco que será criado/utilizado  Serviço da Aplicação:      delivery_management_api: Nome do serviço para a sua aplicação.        build: Indica que o contêiner deve ser construído a partir do Dockerfile localizado no diretório atual (.). O Dockerfile deve estar no mesmo diretório onde o docker-compose.yml está localizado.        ports: Similar ao serviço do postgres, “8080:8080” mapeia a porta 8080 do contêiner para a porta 8080 do host. Isso permite que você acesse sua aplicação pela URL http://localhost:8080.        depends_on: Especifica que o serviço delivery_management_api depende do serviço postgres. Isso garante que o postgres seja iniciado antes da aplicação. No entanto, isso não garante que o postgres esteja totalmente pronto para aceitar conexões quando a aplicação iniciar.        environment: Define variáveis de ambiente para o container. Essas variáveis são passadas para o ambiente da aplicação e podem ser utilizadas para configuração.        SPRING_DATASOURCE_URL: é utilizada para configurar a conexão da aplicação Spring com um banco de dados PostgreSQL.  Vou explicar o item acima:  jdbc: Java Database Connectivity (JDBC) é uma API do Java que permite interações com diferentes bancos de dados;  postgresql: o tipo de banco de dados utilizado;  //: separador que indica o início da parte que contém as informações sobre o host e a porta;  o restante das informações contidas na string dessa URL são: a porta utilizada pelo postgres, o nome do serviço e o nome do banco de dados.Volumes e redes:      Volumes: Define os volumes utilizados pelos serviços. Aqui, postgres_data é um volume que será usado pelo serviço postgres para persistir dados. Ao criar um volume nomeado, você pode gerenciá-lo facilmente e ele persistirá mesmo se os contêineres forem removidos.        Networks (opcional): Esta seção é opcional e permite que você defina redes personalizadas para conectar os serviços. Se você definir uma rede aqui, os serviços podem se comunicar entre si usando seus nomes. No seu exemplo, não há nenhuma rede definida.  O pom.xml da aplicação precisa estar adequado pra proporcionar estrutura pra rodar da maneira que definimos.&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\"         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;groupId&gt;org.danielmesquita&lt;/groupId&gt;    &lt;artifactId&gt;delivery-management-api&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;properties&gt;        &lt;maven.compiler.source&gt;17&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;17&lt;/maven.compiler.target&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;spring.boot.version&gt;3.3.3&lt;/spring.boot.version&gt;    &lt;/properties&gt;    &lt;dependencyManagement&gt;        &lt;dependencies&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;                &lt;version&gt;${spring.boot.version}&lt;/version&gt;                &lt;type&gt;pom&lt;/type&gt;                &lt;scope&gt;import&lt;/scope&gt;            &lt;/dependency&gt;        &lt;/dependencies&gt;    &lt;/dependencyManagement&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.postgresql&lt;/groupId&gt;            &lt;artifactId&gt;postgresql&lt;/artifactId&gt;            &lt;scope&gt;runtime&lt;/scope&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;javax.validation&lt;/groupId&gt;            &lt;artifactId&gt;validation-api&lt;/artifactId&gt;            &lt;version&gt;2.0.1.Final&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;            &lt;artifactId&gt;lombok&lt;/artifactId&gt;            &lt;optional&gt;true&lt;/optional&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;build&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;                &lt;executions&gt;                    &lt;execution&gt;                        &lt;goals&gt;                            &lt;goal&gt;repackage&lt;/goal&gt;                        &lt;/goals&gt;                    &lt;/execution&gt;                &lt;/executions&gt;            &lt;/plugin&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;                &lt;version&gt;3.4.2&lt;/version&gt; &lt;!-- Certifique-se de usar uma versão compatível --&gt;                &lt;configuration&gt;                    &lt;archive&gt;                        &lt;manifest&gt;                            &lt;mainClass&gt;org.danielmesquita.Application&lt;/mainClass&gt; &lt;!-- Defina a sua classe principal --&gt;                        &lt;/manifest&gt;                    &lt;/archive&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;                &lt;version&gt;3.13.0&lt;/version&gt;                &lt;configuration&gt;                    &lt;source&gt;17&lt;/source&gt;                    &lt;target&gt;17&lt;/target&gt;                    &lt;compilerArgs&gt;                        &lt;arg&gt;-parameters&lt;/arg&gt;                    &lt;/compilerArgs&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;&lt;/project&gt;Mantive basicamente a mesma estrutura do pom.xml anterior. Mas neste eu precisei mudar a dependência do banco de dados e também incluir a dependência spring-boot-starter-data-jpa, que inclui o Hibernate e outras utilitários da JPA (Java Persistence API), que são necessárias para persistência de dados das entidades Java no PostgreSQL. Com Hibernate e JPA, podemos interagir com o banco PostgreSQL sem precisar escrever consultas SQL manuais.O Hibernate é um framework ORM (Object-Relational Mapping) que o Spring Boot usa para interagir com banco de dados. Com ele você pode trabalhar com objetos Java, enquanto ele mapeia os objetos para as tabelas do banco de dados, gerenciando as consultas SQL por trás dos panos.Outra inclusão que fiz foi nos plugins do build, incluí o maven-compiler-plugin com a flag -parameters na configuração do compilador para poder usar alguns parâmetros nas urls das requests.Por último na parte de configuração, o application.properties:# Configuração do PostgreSQLspring.datasource.url=jdbc:postgresql://postgres_application:5432/orderdbspring.datasource.driver-class-name=org.postgresql.Driverspring.datasource.username=postgresspring.datasource.password=admin# Dialeto do PostgreSQL para o Hibernatespring.jpa.database-platform=org.hibernate.dialect.PostgreSQLDialect# Inicialização do banco de dadosspring.sql.init.mode=alwaysspring.jpa.defer-datasource-initialization=true# Atualiza o esquema do banco de dados com base nas entidades sempre que a aplicação for iniciadaspring.jpa.hibernate.ddl-auto=updateEu deixei comentado cada bloco pra ficar mais claro e facilitar o entendimento.O arquivo .properties é necessário em algumas aplicações serve para configurar propriedades e comportamentos que podem ser acessados por toda a aplicação.Feito isso, agora vamos ao código da aplicação e as interações com o banco.Na aplicação do MongoDB eu criei só uma entidade pra critério de entendimento. Como se tratava de SQL, e no SQL temos alguns relacionamentos entre tabelas muito úteis de aprender, eu dei uma incrementada, tendo 3 entidades: Product, Order, Category.É basicamente uma estrutura onde teremos produtos, que estão em determinada categoria e que podem ser incluídos em pedidos.Entidades e suas característicasAgora vou compartilhar as entidades.Product:@Entity@Table(name = \"products\")@Data@Builder@ToString(exclude = \"orders\")@EqualsAndHashCode(exclude = \"orders\")@NoArgsConstructor@AllArgsConstructorpublic class Product {  @Id  @GeneratedValue(strategy = GenerationType.IDENTITY)  @Column(name = \"product_id\")  private Long id;  @Column(name = \"product_name\")  private String name;  @Column(name = \"product_price\")  private Double price;  @ManyToOne  @JoinColumn(name = \"category_id\", nullable = false)  @JsonBackReference  private Category category;  @ManyToMany  @JoinTable(      name = \"item_order\",      joinColumns = @JoinColumn(name = \"product_id\"),      inverseJoinColumns = @JoinColumn(name = \"order_id\"))  @JsonIgnore  Set&lt;Order&gt; orders;}Categoryimport com.fasterxml.jackson.annotation.JsonManagedReference;import jakarta.persistence.*;import java.util.List;import lombok.*;@Entity@Table(name = \"category\")@Data@Builder@ToString(exclude = \"products\")@EqualsAndHashCode(exclude = \"products\")@NoArgsConstructor@AllArgsConstructorpublic class Category {  @Id  @GeneratedValue(strategy = GenerationType.IDENTITY)  @Column(name = \"category_id\")  private Long id;  @Column(name = \"category_name\", nullable = false)  private String categoryName;  @OneToMany(mappedBy = \"category\", fetch = FetchType.LAZY)  @JsonManagedReference  private List&lt;Product&gt; products;}Orderimport jakarta.persistence.*;import java.time.LocalDateTime;import java.util.List;import lombok.*;@Entity@Table(name = \"orders\")@Data@Builder@ToString(exclude = \"products\")@EqualsAndHashCode(exclude = \"products\")@NoArgsConstructor@AllArgsConstructorpublic class Order {  @Id  @GeneratedValue(strategy = GenerationType.IDENTITY)  @Column(name = \"order_id\")  private Long id;  @Column(name = \"order_date\")  private LocalDateTime orderDate;  @ManyToMany List&lt;Product&gt; products;}Você viu que é cheio de annotations nessas entidades. Aqui temos algumas anotações referentes a JPA e também ao Lombok. Como nas últimas postagens, eu mostrei todos os métodos de manipulação e leitura para uma entidade, aqui vou usar a biblioteca Lombok para reduzir código repetitivo. Vou explicar cada anotação:      @Entity: Indica que a classe é uma entidade JPA (Java Persistence API) que representa uma tabela no banco de dados.        @Table(name = \"category\"): Especifica o nome da tabela no banco de dados que essa entidade representa.        @Data: Uma anotação do Lombok que gera automaticamente métodos getter, setter, toString, equals, e hashCode para a classe.        @Builder: Permite o uso do padrão de projeto Builder para criar instâncias da entidade de maneira mais legível.        @ToString(exclude = \"products\"): Gera o método toString, mas exclui o atributo products para evitar um loop infinito devido ao relacionamento bidirecional.        @EqualsAndHashCode(exclude = “products”): Gera os métodos equals e hashCode, mas exclui o atributo products para evitar problemas de comparação circular.        @NoArgsConstructor: Gera um construtor sem argumentos. Necessário para o JPA criar instâncias da classe.        @AllArgsConstructor: Gera um construtor que aceita todos os campos da classe como parâmetros.        @Id: Indica que o campo id é a chave primária da entidade. Diferente do MongoDB, este compo não pode ser uma String.        @GeneratedValue(strategy = GenerationType.IDENTITY): Especifica que o valor da chave primária será gerado pelo banco de dados (normalmente em uma coluna de auto-incremento).        @Column(name = \"category_id\"): Mapeia o campo id para a coluna category_id na tabela. Vale também para as outras entidades.        @Column(name = \"category_name\", nullable = false): Mapeia o campo categoryName para a coluna category_name, indicando que não pode ser nulo.        @OneToMany(mappedBy = \"category\"): Define um relacionamento um-para-muitos com a entidade Product. O atributo mappedBy indica que o lado “muitos” (ou seja, Product) possui a chave estrangeira.        @ManyToMany: Define um relacionamento muitos-para-muitos com outra entidade. No caso desta aplicação, significa que um pedido pode conter muitos produtos e um produto pode estar em muitas ordens.        @ManyToOne: Define um relacionamento muitos-para-um com outra entidade. Nosso caso, significa que muitos produtos podem pertencer a uma única categoria.        @JsonManagedReference: Utilizada em relacionamentos bidirecionais, indica que este é o lado “gerenciado” da referência. No momento da serialização JSON, o lado “gerenciado” é incluído, enquanto o lado “back” (referido na outra entidade) será ignorado, neste caso, na entidade Product.        @JsonBackReference: Usada em um relacionamento bidirecional, indica que este é o lado “back” da referência. Durante a serialização JSON, o lado “back” será ignorado, evitando loops infinitos.        @JoinColumn(name = \"category_id\", nullable = false): Especifica a coluna que armazena a chave estrangeira (no caso, category_id é a chave estrangeira referente a tabela de produtos).        @JoinTable(...): Especifica a tabela de junção que relaciona os produtos aos pedidos. O joinColumns define a chave estrangeira da entidade Product, enquanto inverseJoinColumns define a chave estrangeira da entidade Order.        @JsonIgnore: Indica que este campo não deve ser incluído na serialização JSON. É útil para evitar a inclusão de dados que não são necessários ou podem causar loops infinitos na serialização.  Resumo dos RelacionamentosORM (Object Relational Mapper) é uma técnica de mapeamento objeto-relacional que aproxima o desenvolvimento de aplicações orientadas a objetos do paradigma de bancos de dados relacionais (SQL). Geralmente você pode ver esses relacionamentos representados por um diagrama utilizando UML como o item abaixo:      Category para Product: Relacionamento um-para-muitos. Uma categoria pode ter muitos produtos, mas um produto só pode pertencer a uma categoria.        Order para Product: Relacionamento muitos-para-muitos. Uma ordem pode conter muitos produtos, e um produto pode ser parte de muitas ordens.        Product para Category: Relacionamento muitos-para-um. Muitos produtos podem pertencer a uma única categoria.        Product para Order: Relacionamento muitos-para-muitos. Muitos produtos podem estar associados a muitas ordens.  RepositoryNão temos muitas diferenças consideráveis nos repositories desta aplicação em relação a do Mongo. A principal diferenção é que ao invés de extender MongoRepository, vai extender JpaRepository, conforme exemplo abaixo:@Repositorypublic interface CategoryRepository extends JpaRepository&lt;Category, Long&gt; {  Optional&lt;Category&gt; findByCategoryName(String categoryName);}No repository acima, referente a entidade Category, estou extendendo JpaRepository para Category e Long (referente a chave primária do item). Além disso, estou inserido um método personalizado para buscar a categoria pelo nome. Os demais repositories seguem a mesma estrutura.ServiceO service também não tem muita mudança relevante em relação ao caso utilizado na aplicação usando NoSQL porque a regra de negócios não mudou.import java.util.List;import java.util.Optional;import org.danielmesquita.entities.Category;import org.danielmesquita.repository.CategoryRepository;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;@Servicepublic class CategoryService {  @Autowired CategoryRepository categoryRepository;  public List&lt;Category&gt; findAllCategories() {    return categoryRepository.findAll();  }  public Optional&lt;Category&gt; findCategoryById(Long id) {    return categoryRepository.findById(id);  }  public Optional&lt;Category&gt; findCategoryByName(String categoryName) {    return categoryRepository.findByCategoryName(categoryName);  }  public void insertCategory(Category category) {    categoryRepository.save(category);  }  public void deleteCategoryById(Long id) {    categoryRepository.deleteById(id);  }}Um ponto que vale ressaltar é que utilizamos o Optional para evitar NullPointerException caso o item não conste no banco de dados.ControllerNesta parte, temos algumas diferenças em relação a aplicação NoSQL apenas para podermos explorar melhor o relacionamento entre as entidades. Abaixo vou mostrar como ficou cada um.ProductControllerimport java.util.List;import java.util.Optional;import org.danielmesquita.dto.ProductDTO;import org.danielmesquita.entities.Category;import org.danielmesquita.entities.Product;import org.danielmesquita.service.CategoryService;import org.danielmesquita.service.ProductService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.http.HttpStatus;import org.springframework.http.ResponseEntity;import org.springframework.web.bind.annotation.*;import org.springframework.web.server.ResponseStatusException;@RestController@RequestMapping(\"/products\")public class ProductController {  @Autowired private ProductService productService;  @Autowired private CategoryService categoryService;  @PostMapping  public ResponseEntity&lt;Product&gt; createProduct(@RequestBody ProductDTO productDTO) {    Category category =        categoryService            .findCategoryByName(productDTO.getCategory())            .orElseThrow(                () -&gt; new ResponseStatusException(HttpStatus.NOT_FOUND, \"Category not found\"));    Product product =        Product.builder()            .name(productDTO.getName())            .price(productDTO.getPrice())            .category(category)            .build();    productService.insertProduct(product);    return new ResponseEntity&lt;&gt;(product, HttpStatus.CREATED);  }  @GetMapping  public ResponseEntity&lt;List&lt;Product&gt;&gt; getAllProducts() {    List&lt;Product&gt; products = productService.findAllProducts();    return new ResponseEntity&lt;&gt;(products, HttpStatus.OK);  }  @GetMapping(\"/{id}\")  public ResponseEntity&lt;Product&gt; getProductById(@PathVariable Long id) {    Optional&lt;Product&gt; product = productService.findProductById(id);    return product.map(ResponseEntity::ok).orElseGet(() -&gt; ResponseEntity.notFound().build());  }  @PutMapping(\"/{id}\")  public ResponseEntity&lt;Product&gt; updateProduct(      @PathVariable Long id, @RequestBody Product product) {    product.setId(id);    productService.updateProduct(product);    return new ResponseEntity&lt;&gt;(product, HttpStatus.OK);  }  @DeleteMapping(\"/{id}\")  public ResponseEntity&lt;Void&gt; deleteProduct(@PathVariable Long id) {    productService.deleteProduct(id);    return new ResponseEntity&lt;&gt;(HttpStatus.NO_CONTENT);  }}CategoryControllerimport java.util.ArrayList;import java.util.List;import java.util.Optional;import org.danielmesquita.dto.CategoryDTO;import org.danielmesquita.entities.Category;import org.danielmesquita.entities.Product;import org.danielmesquita.service.CategoryService;import org.danielmesquita.service.ProductService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.http.HttpStatus;import org.springframework.http.ResponseEntity;import org.springframework.web.bind.annotation.*;import org.springframework.web.server.ResponseStatusException;@RestController@RequestMapping(\"/categories\")public class CategoryController {  @Autowired private CategoryService categoryService;  @Autowired private ProductService productService;  @PostMapping  public ResponseEntity&lt;Category&gt; createCategory(@RequestBody CategoryDTO categoryDTO) {    List&lt;Product&gt; products = populateProductList(categoryDTO);    Category category =        Category.builder()            .categoryName(categoryDTO.getName())            .products(setProductsListToBuild(products))            .build();    categoryService.insertCategory(category);    return new ResponseEntity&lt;&gt;(category, HttpStatus.CREATED);  }  @GetMapping  public ResponseEntity&lt;List&lt;Category&gt;&gt; getAllCategories() {    List&lt;Category&gt; categories = categoryService.findAllCategories();    return new ResponseEntity&lt;&gt;(categories, HttpStatus.OK);  }  @GetMapping(\"/{id}\")  public ResponseEntity&lt;Category&gt; getCategoryById(@PathVariable Long id) {    Optional&lt;Category&gt; category = categoryService.findCategoryById(id);    return category.map(ResponseEntity::ok).orElseGet(() -&gt; ResponseEntity.notFound().build());  }  @PutMapping(\"/{id}\")  public ResponseEntity&lt;Category&gt; updateCategory(      @PathVariable Long id, @RequestBody Category categoryDetails) {    Optional&lt;Category&gt; category = categoryService.findCategoryById(id);    if (category.isPresent()) {      Category existingCategory = category.get();      existingCategory.setCategoryName(categoryDetails.getCategoryName());      categoryService.insertCategory(existingCategory);      return new ResponseEntity&lt;&gt;(existingCategory, HttpStatus.OK);    } else {      return new ResponseEntity&lt;&gt;(HttpStatus.NOT_FOUND);    }  }  @DeleteMapping(\"/{id}\")  public ResponseEntity&lt;Void&gt; deleteCategory(@PathVariable Long id) {    categoryService.deleteCategoryById(id);    return new ResponseEntity&lt;&gt;(HttpStatus.NO_CONTENT);  }  public List&lt;Product&gt; populateProductList(CategoryDTO categoryDTO) {    List&lt;Product&gt; products = new ArrayList&lt;&gt;();    if (categoryDTO.getProductIdList() != null &amp;&amp; !categoryDTO.getProductIdList().isEmpty()) {      for (Long productId : categoryDTO.getProductIdList()) {        Product product =            productService                .findProductById(productId)                .orElseThrow(                    () -&gt;                        new ResponseStatusException(                            HttpStatus.NOT_FOUND, \"Product with ID \" + productId + \" not found\"));        products.add(product);      }    }    return products;  }  public List&lt;Product&gt; setProductsListToBuild(List&lt;Product&gt; products) {    if (products.isEmpty()) {      return null;    }    return products;  }}OrderControllerimport java.util.ArrayList;import java.util.List;import java.util.Optional;import org.danielmesquita.dto.OrderDTO;import org.danielmesquita.entities.Order;import org.danielmesquita.entities.Product;import org.danielmesquita.service.OrderService;import org.danielmesquita.service.ProductService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.http.HttpStatus;import org.springframework.http.ResponseEntity;import org.springframework.web.bind.annotation.*;import org.springframework.web.server.ResponseStatusException;@RestController@RequestMapping(\"/orders\")public class OrderController {  @Autowired private OrderService orderService;  @Autowired private ProductService productService;  @PostMapping  public ResponseEntity&lt;Order&gt; createNewOrder(@RequestBody OrderDTO orderDTO) {    if (orderDTO.getProductIdList() == null) {      throw new ResponseStatusException(HttpStatus.BAD_REQUEST, \"Product list cannot be empty\");    }    List&lt;Product&gt; products = populateProductList(orderDTO);    Order order = Order.builder().orderDate(orderDTO.getDate()).products(products).build();    orderService.insertOrder(order);    return new ResponseEntity&lt;&gt;(order, HttpStatus.CREATED);  }  @GetMapping  public ResponseEntity&lt;List&lt;Order&gt;&gt; getAllOrders() {    List&lt;Order&gt; orders = orderService.findAllOrders();    return new ResponseEntity&lt;&gt;(orders, HttpStatus.OK);  }  @PutMapping(\"/{id}\")  public ResponseEntity&lt;Order&gt; updateOrder(      @PathVariable Long id, @RequestBody OrderDTO orderDetails) {    Optional&lt;Order&gt; order = orderService.findOrderById(id);    if (order.isPresent()) {      Order existingOrder = order.get();      existingOrder.setOrderDate(orderDetails.getDate());      List&lt;Product&gt; products = populateProductList(orderDetails);      existingOrder.setProducts(products);      orderService.insertOrder(existingOrder);      return new ResponseEntity&lt;&gt;(existingOrder, HttpStatus.OK);    } else {      return new ResponseEntity&lt;&gt;(HttpStatus.NOT_FOUND);    }  }  @DeleteMapping(\"/{id}\")  public ResponseEntity&lt;Void&gt; deleteOrder(@PathVariable Long id) {    orderService.deleteOrderById(id);    return new ResponseEntity&lt;&gt;(HttpStatus.NO_CONTENT);  }  public List&lt;Product&gt; populateProductList(OrderDTO orderDTO) {    List&lt;Product&gt; products = new ArrayList&lt;&gt;();    if (!orderDTO.getProductIdList().isEmpty()) {      for (Long productId : orderDTO.getProductIdList()) {        Product product =            productService                .findProductById(productId)                .orElseThrow(                    () -&gt;                        new ResponseStatusException(                            HttpStatus.NOT_FOUND, \"Product with ID \" + productId + \" not found\"));        products.add(product);      }    }    return products;  }}As anotações referentes ao Spring Boot para o controlador se mantém, se tiver dúvidas, consulte na postagem anterior. O principal ponto é que aqui eu incluí DTOs (data transfer objects) para otimizar as requisições, evitando que seja necessário incluir todas as informações de todos os objetos que as entidades formam. Além disso, esses DTOs facilitam construir o relacionamento entre as entidades utilizando apenas os dados necessários.Uma boa prática de programação neste caso seria remover as manipulações de dados, principalmente a de outras entidades, dos controllers e mandar para os services. As classes de service que devem conter as regras de negócio, então se uma categoria vai incluir produtos ou não, como as interações entre os dados de uma entidade e outra serão feitas, devem ir pra lá. Deixei aqui mais pra mostrar a ideia de como funciona.No repositório do GitHub desta aplicação, já vou deixar como eu refatoraria esse código que mostrei aqui.Depois disso é só mandar um docker-compose down -v pra derrubar o container e apagar todos os dados persistidos no banco de dados pra começar do zero (caso não queira apagar os dados, só remover o -v do comando), depois mvn clean install pra instalar tudo que precisa e manda um docker-compose up --build e pode brincar com sua aplicação fazendo requisições HTTP via linha de comando ou usando alguma ferramenta feito o postman.É isso, essa aqui foi uma postagem mais densa porque tem alguns conceitos importantes de JPA e SQL que precisavam ser refinados e eu não ia fazer uma nova pra quebrar a linha de raciocínio. Vou deixar aqui embaixo os links dos repositórios no GitHub das aplicações que construí nessa série pra quem tiver interesse em olhar o código, se quiser clonar, melhorar, abrir issue…Aplicação Java com MongoDB rodando localAplicação Java com PostgreSQL rodando localAplicação Spring Boot com MongoDB rodando via docker composeAplicação Spring Boot com PostgreSQL rodando via docker composeEspero que quem leia essas postagens (se alguém ler) faça um bom proveito. Pra mim foi muito bom para aprender, testar e praticar algumas coisas.Abraço!"
  },
  
  {
    "title": "Conectando bancos de dados locais - Parte VI",
    "url": "/posts/database-local-connection-pt-VI/",
    "categories": "Programação, Banco de dados, Docker",
    "tags": "programação, mongodb, banco de dados, nosql, docker, container",
    "date": "2024-09-25 09:00:00 -0300",
    





    
    "snippet": "Depois de dar uma breve introdução da utilização do Docker e docker compose para subir a aplicação em um container, agora vamos ao detalhamento da aplicação de teste usando o MongoDB.Primeiro, para...",
    "content": "Depois de dar uma breve introdução da utilização do Docker e docker compose para subir a aplicação em um container, agora vamos ao detalhamento da aplicação de teste usando o MongoDB.Primeiro, para ficar preciso para a aplicação específica, precisei fazer algumas modificações para o build, vou mostrar abaixo como ficou o Dockerfile, o docker-compose.yml e o próprio pom.xml da aplicação.Dockerfile:# Use uma imagem base adequadaFROM openjdk:17-jdk-slim# Defina o diretório de trabalho dentro do containerWORKDIR /app# Copie o arquivo JAR gerado pelo Maven/GradleCOPY target/delivery-management-api-mongo-1.0-SNAPSHOT.jar app.jar# Defina o comando de inicializaçãoENTRYPOINT [\"java\", \"-jar\", \"app.jar\"]Essa imagem do openjdk:17 é uma versão “slim”, que é mais leve e adequada para a maioria das aplicações.O ENTRYPOINT deve ser ajustado para refletir o caminho correto dentro do container, atenção nisso.docker-compose.yml:version: '3.9'services:  mongo:    image: mongo:latest    ports:      - \"27017:27017\"    volumes:      - mongo_data:/data/db  # Persistir dados do MongoDB  delivery_management_api:    build: .    ports:      - \"8080:8080\"    depends_on:      - mongo    environment:      - SPRING_DATA_MONGODB_URI=mongodb://mongo:27017/spring-test      - SPRING_DATA_MONGODB_DATABASE=spring-testvolumes:  mongo_data:networks:  app-network:  Versão: Especifica a versão da sintaxe do Docker Compose que você está utilizando. A versão 3.9 é uma das versões mais recentes, oferecendo suporte a muitos recursos, como redes e volumes.  Services: Esta seção define os contêineres que serão executados. Cada contêiner é uma instância de um serviço.Serviço MongoDB:      mongo: O nome do serviço. Este é o nome que você usará para referenciar este contêiner.        image: Especifica a imagem do Docker a ser utilizada.        mongo:latest indica que a última versão da imagem oficial do MongoDB será baixada e utilizada. Caso você já tenha uma imagem do MongoDB localmente, essa imagem será usada.        ports: Mapeia as portas do contêiner para as portas da máquina host. “27017:27017” significa que a porta 27017 do contêiner (padrão do MongoDB) será acessível na porta 27017 do host. Isso permite que você acesse o MongoDB de fora do contêiner, por exemplo, utilizando um cliente MongoDB.        volumes: Mapeia um volume do Docker, o que permite a persistência de dados. mongo_data:/data/db indica que o volume chamado mongo_data será utilizado para armazenar os dados do MongoDB no diretório /data/db dentro do contêiner. Isso significa que, mesmo que o contêiner seja destruído, os dados persistem no volume.  Serviço da Aplicação:      delivery_management_api: Nome do serviço para a sua aplicação.        build: Indica que o contêiner deve ser construído a partir do Dockerfile localizado no diretório atual (.). O Dockerfile deve estar no mesmo diretório onde o docker-compose.yml está localizado.        ports: Similar ao serviço MongoDB, “8080:8080” mapeia a porta 8080 do contêiner para a porta 8080 do host. Isso permite que você acesse sua aplicação pela URL http://localhost:8080.        depends_on: Especifica que o serviço delivery_management_api depende do serviço mongo. Isso garante que o MongoDB seja iniciado antes da aplicação. No entanto, isso não garante que o MongoDB esteja totalmente pronto para aceitar conexões quando a aplicação iniciar.        environment: Define variáveis de ambiente para o contêiner. Essas variáveis são passadas para o ambiente da aplicação e podem ser utilizadas para configuração.        SPRING_DATA_MONGODB_URI: URL de conexão ao MongoDB. Aqui, mongodb://mongo:27017/spring-test indica que a aplicação deve se conectar ao serviço MongoDB nomeado mongo na porta 27017 e usar o banco de dados spring-test.        SPRING_DATA_MONGODB_DATABASE: Nome do banco de dados a ser utilizado pela aplicação.  Volumes e redes:      Volumes: Define os volumes utilizados pelos serviços. Aqui, mongo_data é um volume que será usado pelo serviço mongo para persistir dados. Ao criar um volume nomeado, você pode gerenciá-lo facilmente e ele persistirá mesmo se os contêineres forem removidos.        Networks (opcional): Esta seção é opcional e permite que você defina redes personalizadas para conectar os serviços. Se você definir uma rede aqui, os serviços podem se comunicar entre si usando seus nomes. No seu exemplo, não há nenhuma rede definida.  Subir a aplicação usando o docker-compose facilita muito a vida da pessoa desenvolvedora em inúmeros aspectos. Um deles é não se preocupar com ambiente local de desenvolvimento, uma vez que vai rodar tudo no container definido.Com a configuração do Docker e docker compose funcionando (testei a aplicação e chamadas no banco) agora vamos aos ajustes da aplicação para utilização do Springboot, algo que vai diminuir muito a complexidade de código e facilitar a estrutura da aplicação.Primeiro, podemos dar adeus a classe de configuração do banco de dados, uma vez que usando o framework e o Docker, não precisamos construir os relacionamentos manualmente.O pom.xml da aplicação precisa estar adequado pra proporcionar estrutura pra rodar da maneira que definimos.&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\"         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;groupId&gt;org.danielmesquita&lt;/groupId&gt;    &lt;artifactId&gt;delivery-management-api-mongo&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;properties&gt;        &lt;maven.compiler.source&gt;17&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;17&lt;/maven.compiler.target&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;spring.boot.version&gt;3.1.4&lt;/spring.boot.version&gt; &lt;!-- Defina a versão do Spring Boot --&gt;    &lt;/properties&gt;    &lt;dependencyManagement&gt;        &lt;dependencies&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;                &lt;version&gt;${spring.boot.version}&lt;/version&gt;                &lt;type&gt;pom&lt;/type&gt;                &lt;scope&gt;import&lt;/scope&gt;            &lt;/dependency&gt;        &lt;/dependencies&gt;    &lt;/dependencyManagement&gt;    &lt;dependencies&gt;        &lt;!-- Spring Boot Starter for MongoDB --&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;!-- Spring Boot Starter for Web (caso queira construir APIs RESTful) --&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;!-- Validação (javax) --&gt;        &lt;dependency&gt;            &lt;groupId&gt;javax.validation&lt;/groupId&gt;            &lt;artifactId&gt;validation-api&lt;/artifactId&gt;            &lt;version&gt;2.0.1.Final&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;build&gt;        &lt;plugins&gt;            &lt;!-- Plugin do Spring Boot --&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;                &lt;executions&gt;                    &lt;execution&gt;                        &lt;goals&gt;                        &lt;!-- O elemento &lt;goal&gt; especifica qual tarefa o plugin deve realizar. No seu exemplo, você está utilizando o goal repackage. --&gt;                            &lt;goal&gt;repackage&lt;/goal&gt;                        &lt;/goals&gt;                    &lt;/execution&gt;                &lt;/executions&gt;            &lt;/plugin&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;                &lt;version&gt;3.4.2&lt;/version&gt; &lt;!-- Certifique-se de usar uma versão compatível --&gt;                &lt;configuration&gt;                    &lt;archive&gt;                        &lt;manifest&gt;                            &lt;mainClass&gt;org.danielmesquita.Application&lt;/mainClass&gt; &lt;!-- Defina a sua classe principal --&gt;                        &lt;/manifest&gt;                    &lt;/archive&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;&lt;/project&gt;O goal repackage do spring-boot-maven-plugin tem uma relação importante com o Docker e o Docker Compose, especialmente quando se trata de empacotar e executar sua aplicação Spring Boot em um container:  cria um arquivo .jar executável que contém toda a aplicação, permitindo que execute a aplicação Spring em qualquer ambiente com o Java instalado;  com o .jar executável, você pode facilmente executar sua aplicação Spring Boot no container com um único comando, como java -jar app.jar. Isso simplifica o processo de inicialização da aplicação no ambiente Docker;  quando você executa docker-compose up, o Compose irá construir a imagem da aplicação usando o Dockerfile, onde o JAR já foi criado pelo Maven com o goal repackage. Isso significa que você não precisa se preocupar em construir e gerenciar o JAR separadamente, pois o Docker faz isso por você;  usar o repackage e Docker em conjunto garante que você tenha um ambiente de execução consistente e portátil, você pode mover o container para qualquer máquina que tenha o Docker, e sua aplicação Spring Boot funcionará exatamente da mesma forma, com todas as suas dependências já incluídas no JAR.Você pode rodar sem usar o repackage, mas algumas desvantagens que vejo é aumento da complexidade pra gerenciar dependências, imagens maiores e probabilidade maior de erro devido a gerenciamento errado das imagens.Com a estrutura da aplicação pronta pra usar o Spring e rodar no Docker, podemos ir ao código.Primeiro, precisamos ajustar a classe principal (que roda a aplicação) para configurar o Spring Boot. Nas versões anteriores, eu fiz alguns códigos nelas pra mostrar as alterações no banco, aqui não vou fazer isso. Vou usar a arquitetura em camadas, separando as responsabilidades entre Repository, Service e Controller adequadamente.import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class Application {  public static void main(String[] args) {    SpringApplication.run(Application.class, args);  }}A entidade “Product” sofre algumas alterações para incluir para podermos utilizar o Spring Boot e o Mongo, uma vez que o framework proporciona recursos para interação com o banco exigindo menos código boilerplate.Os getters, setters, construtores etc se mantém, o que muda é a anotação @Document do mongo que define que aquela entidade representa a coleção Product no meu banco de dados. Além disso, o atributo id recebe a anotação @Id, responsável pela geração automática do id único dentro da coleção.import javax.validation.constraints.NotNull;import javax.validation.constraints.Size;import org.springframework.data.annotation.Id;import org.springframework.data.mongodb.core.mapping.Document;@Document(collection = \"Product\")public class Product {  @Id private String id;  @NotNull(message = \"Product name is required\")  private String name;  @NotNull(message = \"Product price is required\")  private Double price;  @NotNull(message = \"Product description is required\")  @Size(min = 10, message = \"Product description requires 10 characters at least\")  private String description;  private String imageUri;  public Product() {}  public Product(String id, String name, Double price, String description, String imageUri) {    this.id = id;    this.name = name;    this.price = price;    this.description = description;    this.imageUri = imageUri;  }  public String getId() {    return id;  }  public void setId(String id) {    this.id = id;  }  public String getName() {    return name;  }  public void setName(String name) {    this.name = name;  }  public Double getPrice() {    return price;  }  public void setPrice(Double price) {    this.price = price;  }  public String getDescription() {    return description;  }  public void setDescription(String description) {    this.description = description;  }  public String getImageUri() {    return imageUri;  }  public void setImageUri(String imageUri) {    this.imageUri = imageUri;  }  public boolean validateId(String id) {    return id != null &amp;&amp; !id.isEmpty();  }}A classe ProductRepository também sofre alteração e fica bem mais simplificada, considerando o propósito desta aplicação. Aqui estou transformando em uma interface que extende a interface MongoRepository, que já contém os métodos necessários para interação com o banco. Mas é possível inserir alguns métodos personalizados como os exemplos abaixo.import java.util.List;import org.danielmesquita.entities.Product;import org.springframework.data.mongodb.repository.MongoRepository;import org.springframework.stereotype.Repository;@Repositorypublic interface ProductRepository extends MongoRepository&lt;Product, String&gt; {  List&lt;Product&gt; findByName(String name);  List&lt;Product&gt; findByPrice(Double price);  List&lt;Product&gt; findByDescriptionContaining(String description);}Agora a classe de Service, onde estão as regras de negócio da aplicação e que orquestra a interação entre repository e Controller:import java.util.List;import org.danielmesquita.entities.Product;import org.danielmesquita.repository.ProductRepository;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.mongodb.core.MongoTemplate;import org.springframework.stereotype.Service;@Servicepublic class ProductService {  @Autowired private ProductRepository productRepository;  @Autowired private MongoTemplate mongoTemplate;  public void insertProduct(Product product) {    productRepository.save(product);  }  public Product findProductById(String id) {    return productRepository.findById(id).orElse(null);  }  public List&lt;Product&gt; findAllProducts() {    return productRepository.findAll();  }  public void updateProduct(Product product) {    productRepository.save(product);  }  public void deleteProduct(String id) {    productRepository.deleteById(id);  }}E por último, o Controller que recebe as requisições HTTP (GET, POST, PUT, DELETE), processa e devolve as respostas.import java.util.List;import org.danielmesquita.entities.Product;import org.danielmesquita.service.ProductService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.http.HttpStatus;import org.springframework.http.ResponseEntity;import org.springframework.web.bind.annotation.*;@RestController@RequestMapping(\"/api/products\")public class ProductController {  @Autowired private ProductService productService;  @PostMapping  public ResponseEntity&lt;Product&gt; createProduct(@RequestBody Product product) {    productService.insertProduct(product);    return new ResponseEntity&lt;&gt;(product, HttpStatus.CREATED);  }  @GetMapping  public ResponseEntity&lt;List&lt;Product&gt;&gt; getAllProducts() {    List&lt;Product&gt; products = productService.findAllProducts();    return new ResponseEntity&lt;&gt;(products, HttpStatus.OK);  }  @GetMapping(\"/{id}\")  public ResponseEntity&lt;Product&gt; getProductById(@PathVariable String id) {    Product product = productService.findProductById(id);    return product != null        ? new ResponseEntity&lt;&gt;(product, HttpStatus.OK)        : new ResponseEntity&lt;&gt;(HttpStatus.NOT_FOUND);  }  @PutMapping(\"/{id}\")  public ResponseEntity&lt;Product&gt; updateProduct(      @PathVariable String id, @RequestBody Product product) {    product.setId(id);    productService.updateProduct(product);    return new ResponseEntity&lt;&gt;(product, HttpStatus.OK);  }    @DeleteMapping(\"/{id}\")  public ResponseEntity&lt;Void&gt; deleteProduct(@PathVariable String id) {    productService.deleteProduct(id);    return new ResponseEntity&lt;&gt;(HttpStatus.NO_CONTENT);  }}Aqui usei a anotação @RestController do Spring, que é uma especialização de @Controller.A anotação @Controller é mais adequada para para um controlador MVC (Model-View-Control), que retorna views, geralmente HTML. Pra quem usa JSP, deve ser familiar isso.A diferença é que o que optei utilizar é mais adequado para APIs RESTful. Combina o @Controller e @ResponseBody, permitindo retornar dados diretamente no corpo da resposta, geralmente em JSON, mas pode ser em XML também.Outro ponto foi que utilizei a anotação @Autowired para injeção de dependências. Ela vai fornecer automaticamente uma instância da classe que preciso, neste caso é ProductService.As principais vantagens de usar essa anotação é a redução de acoplamento, uma vez que você pode fazer alteração no service sem mexer no controller, e facilidade para testar e criar mocks.E é isso, galera. A intenção era fazer só mais uma postagem mostrando os dois casos de uso (Mongo e PostgreSQL), mas pra não ficar muito extenso. Vou encerrar por aqui. Depois trago o caso de uso com o postgres. Vai ser mais curto, uma vez que já passamos pelo conceito e uso do Docker e docker compose.Abraço!"
  },
  
  {
    "title": "Conectando bancos de dados locais - Parte V",
    "url": "/posts/database-local-connection-pt-V/",
    "categories": "Programação, Banco de dados, Docker",
    "tags": "programação, mongodb, postgres, banco de dados, nosql, sql docker, container",
    "date": "2024-09-14 16:00:00 -0300",
    





    
    "snippet": "Eu pretendia encerrar esta série de postagens sobre conexão local de banco de dados com Java para desenvolvedores trabalharem em seus projetos de estudo. Mas algumas contribuições levantaram alguns...",
    "content": "Eu pretendia encerrar esta série de postagens sobre conexão local de banco de dados com Java para desenvolvedores trabalharem em seus projetos de estudo. Mas algumas contribuições levantaram alguns assuntos que eu ainda achei interessante trazer: subir os bancos no Docker pra evitar instalação local e demonstrar como fazer a conexão utilizando Springboot.A lógica de eu ter abordado primeiro sem Docker é para não incluir uma camada maior de complexidade no assunto abordado. Uma vez que fala-se de Docker, tem que explicar o que faz, o que é um container entre outras coisas.A mesma coisa é sobre aplicação de framework. Apesar de ele diminuir a complexidade, incluir um framework na jogada deixa muita coisa “por baixo dos panos”, o que acaba tirando a compreensão real do que está sendo feito.Mas passando essas explicações, vamos lá.Imagine o container de transporte de carga dentro de um navio. Se um deles é danificado, os demais se mantem intactos. A lógica é semelhante para o desenvolvimento. Um container é um ambiente isolado, com sua responsabilidade específica e caso um sofra um dano, o funcionamento do sistema não para e a função afetada pode ser redirecionada para outro container. Eles isolam um único aplicativo e suas dependências – todas as bibliotecas externas de software que o aplicativo precisa executar – tanto do sistema operacional subjacente quanto de outros containers.Onde o Docker entra nessa história de container?O Docker utiliza o kernel do Linux entre outras coisas para segregar processos, permitindo que eles sejam executados de maneira independente. Utilizando um modelo de implantação baseado em imagens, facilita o compartilharamento de uma aplicação, serviços e suas dependências, além de automatizar a implantação dentro desse ambiente de container.Tudo isso proporciona um uso eficiente dos recursos do sistema, utilização de memória mais eficiente que máquinas virtuais, economia de recursos, facilidade de implantação de aplicações.Tendo esta breve explicação, o Docker hoje tem duas maneiras de utilização. A primeira é pelo Docker Engine, que age como uma aplicação cliente-servidor, fornecendo um CLI que utiliza as APIs do Docker para realizar os comandos. Utilizar o Docker Engine puro só é possível no Linux e para deixar no ponto só fazer o seguinte (usando o Ubuntu como exemplo). Primeiro passo é desinstalar versões conflitantes dos packages ou distribuições não oficiais:for pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; do sudo apt-get remove $pkg; doneDepois você pode instalar a versão mais recente:sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-pluginPra verificar se tá tudo certo, roda o comando abaixo, que vai criar uma imagem de teste e rodar em um container. Quando o container rodar, ele printa uma mensagem de confirmação e finaliza.sudo docker run hello-worldJá pra usar Docker Engine via versão aplicação desktop, é só você seguir a documentação de instalação dependendo do seu sistema operacional.Você pode rodar ambos os bancos de dados que falei aqui de duas maneiras: implantação da imagem via CLI (ou Docker Desktop) ou usando o Docker Compose para fazer gestão de multi-containeres, que permite que a aplicação suba o banco de acordo com o ambiente em execução. o Docker Compose já vem na instalação padrão, inclusive na aplicação desktop.Vou começar explicando pelo Docker Compose, porque através dele, você pode configurar tanto o mongo quanto o postegres, uma vez que ele roda seus containeres de maneira isolada para a aplicação.Primeiro passo é criar um arquivo Dockerfile para que o ambiente possa rodar em qualquer lugar. Um exemplo:FROM adoptopenjdk/openjdk11:latestARG JAR_FILE=target/your-application.jarCOPY ${JAR_FILE} app.jarENTRYPOINT [\"java\",\"-jar\",\"/app.jar\"]Aqui neste arquivo estou definindo a versão da JDK que vai ser utilizada e os comandos para rodar a aplicação.O segundo passo é definir os serviços que suportam a aplicação em um arquivo yml por exemplo docker-compose.yml para que esses serviços rodem junto a sua aplicação em um ambiente isolado. No exemplo abaixo, mostro uma ideia de como configurar os dois bancos em um arquivo yml para poder usar o Docker Compose:version: \"3.9\"volumes:  postgres_data:    driver: local  mongo_data:    driver: localservices:  mongodb_application:    container_name: mongodb_application    build: ./Dockerfile    restart: always    ports:      - \"27017:27017\"    healthcheck:      test: test $$(echo \"rs.initiate().ok || rs.status().ok\" | mongo -u admin -p pass --quiet) -eq 1      interval: 10s      start_period: 30s    environment:      MONGO_INITDB_ROOT_USERNAME: admin      MONGO_INITDB_ROOT_PASSWORD: pass      MONGO_INITDB_DATABASE: test    volumes:      - ./docker-initdb/mongo-init.js:/docker-initdb/mongo-init.js:ro      - mongo_data:/data/db  postgres_application:    container_name: postgres_application    image: postgres    volumes:      - postgres_data:/var/lib/postgresql/data    environment:      POSTGRES_DB: application      POSTGRES_USER: admin      POSTGRES_PASSWORD: pass    ports:      - \"5432:5432\"Vale notar que no caso do mongo, na parte dos volumes, estou usando um exemplo de script para inicialização do banco:print('Start #################################################################');db = db.getSiblingDB('application');db.createUser(    {        user: 'user',        pwd: 'pass',        roles: [{ role: 'readWrite', db: 'application' }],    },);Com isso tudo no ponto, estando bem configurado, é só rodar um docker compose up e o Compose vai iniciar sua aplicação inteira, com as dependências de bancos de dados rodando para sua necessidade.Vale ressaltar que usar o compose permite que você separe ambientes específicos e que para rodar o seu banco específico tem outros passos que vai depender da sua aplicação. Coisa que vai ficar para o próximo post quando eu for falar sobre utilização do Springboot para configurar os bancos.Agora se você não quer usar o Compose por algum motivo, podemos fazer a implantação dos bancos via CLI do Docker. Para o postegres é o seguinte. Primeiro você deve baixar e executar a imagem do PostgreSQL, execute o comando abaixo para baixar a imagem e rodar o container:docker run --name meu-postgres -e POSTGRES_PASSWORD=minha_senha -d -p 5432:5432 postgres  --name meu-postgres dá um nome ao container.  -e POSTGRES_PASSWORD=minha_senha define a senha do usuário postgres.  -d faz o container rodar em segundo plano.  -p 5432:5432 mapeia a porta do container para a máquina local (5432 é a porta padrão do PostgreSQL).  postgres é o nome da imagem oficial do PostgreSQL.Para acessar após rodar o container, você pode usar o psql ou acessar diretamente dentro do container.Via psql e aí você usa a senha que você definiu ao subir o container:psql -h localhost -U postgresDentro do container e usar o psql diretamente lá:docker exec -it meu-postgres bashpsql -U postgresSe você quiser persistir os dados entre as reinicializações do container, você pode montar um volume assim:docker run --name meu-postgres -e POSTGRES_PASSWORD=minha_senha -d -p 5432:5432 -v /meu/caminho/para/volume:/var/lib/postgresql/data postgresIsso garante que os dados do PostgreSQL fiquem armazenados localmente em /meu/caminho/para/volume.Agora vamos para o caso do Mongo. Primeiro precisa extrair a imagem do Docker do MongoDB:docker pull mongodb/mongodb-community-server:latestAgora pode executar a imagem em um container:docker run --name mongodb -p 27017:27017 -d mongodb/mongodb-community-server:latestO -p 27017:27017 neste comando mapeia a porta do contêiner para a porta do host. Isso permite que você conecte o MongoDB com uma connection string do localhost:27017.Verifique se o container está em execução:docker container lsA saída deve ser algo mais ou menos assim:CONTAINER ID   IMAGE                                       COMMAND                  CREATED         STATUS         PORTS       NAMESc29db5687290   mongodb/mongodb-community-server:5.0-ubi8   \"docker-entrypoint.s…\"   4 seconds ago   Up 3 seconds   27017/tcp   mongoConecte-se ao MongoDB Deployment com mongosh:mongosh --port 27017Valide sua implementação com:db.runCommand(   {      hello: 1   })O resultado deve ser um doc assim:{   isWritablePrimary: true,   topologyVersion: {      processId: ObjectId(\"63c00e27195285e827d48908\"),      counter: Long(\"0\")},   maxBsonObjectSize: 16777216,   maxMessageSizeBytes: 48000000,   maxWriteBatchSize: 100000,   localTime: ISODate(\"2023-01-12T16:51:10.132Z\"),   logicalSessionTimeoutMinutes: 30,   connectionId: 18,   minWireVersion: 0,   maxWireVersion: 20,   readOnly: false,   ok: 1}Antes de sair escrevendo código. Recomendo você estudar um pouco mais sobre containeres e Docker, recomendo ler a própria documentação do Docker que é bem completinha. Vou deixar esse assunto ser digerido mais um pouco pra depois partir para uma abordagem prática na aplicação exemplo que estou utilizando. Além disso, pesquise por conta própria sobre as instalações se tiver alguma dúvida. Se você tiver preguiça de pesquisar, você é um péssimo desenvolvedor.Um ponto importante é que após finalizada esta série, eu vou disponibilizar no meu Github uma versão testada e funcional de uma aplicação simples que utiliza tudo o que falamos aqui. Então pode ser que no próximo (e último post desta série) eu já traga ela para vocês.Abraços!"
  },
  
  {
    "title": "Conectando bancos de dados locais - Parte IV",
    "url": "/posts/database-local-connection-pt-IV/",
    "categories": "Programação, Banco de dados",
    "tags": "programação, mongodb, banco de dados, nosql",
    "date": "2024-09-05 17:00:00 -0300",
    





    
    "snippet": "Hoje vou finalizar o conteúdo sobre MongoDB com Java rodando local. A parte grossa de instalação e configuração já foi. Agora é só configurar as entidades, criar os métodos necessários e botar pra ...",
    "content": "Hoje vou finalizar o conteúdo sobre MongoDB com Java rodando local. A parte grossa de instalação e configuração já foi. Agora é só configurar as entidades, criar os métodos necessários e botar pra rodar. Então sem enrolação demais, vamos para o código.Como estou usando uma abordagem sem framework, o código acaba ficando um pouco mais chato mesmo de escrever, mas aqui o objetivo não é conteúdo de Spring, veremos coisas assim no futuro. Aqui vai a classe interage com o banco de dados.Nela eu declaro o atributo MongoCollection que é a interface da API do mongo que orquestra coleções. É uma collection de Document, por isso o &lt;Document&gt;. Chamo o construtor da classe que faz a conexão com o banco em DB.getConnection() e depois defino a coleção que vamos usar de acordo com a variável COLLECTION_NAME.Os métodos são bem semelhantes na abordagem, interagem com o banco criando, lendo, editando e deletando valores.import static com.mongodb.client.model.Filters.eq;import com.mongodb.client.MongoCollection;import com.mongodb.client.MongoDatabase;import java.util.ArrayList;import java.util.List;import org.bson.Document;import org.bson.types.ObjectId;import org.danielmesquita.dbconfig.DB;import org.danielmesquita.entities.Product;public class ProductRepository {  private final MongoCollection&lt;Document&gt; collection;  private static final String COLLECTION_NAME = \"products\";  public static final String NAME_FIELD = \"name\";  public static final String PRICE_FIELD = \"price\";  public static final String DESCRIPTION_FIELD = \"description\";  public static final String IMAGE_URI_FIELD = \"imageUri\";  public static final String ID_FIELD = \"_id\";  public ProductRepository() {    MongoDatabase database = DB.getConnection();    this.collection = database.getCollection(COLLECTION_NAME);  }  public void insertProduct(Product product) {    Document document =        new Document(NAME_FIELD, product.getName())            .append(PRICE_FIELD, product.getPrice())            .append(DESCRIPTION_FIELD, product.getDescription())            .append(IMAGE_URI_FIELD, product.getImageUri());    collection.insertOne(document);  }  public Product findProductById(String id) {    ObjectId objectId = new ObjectId(id);    Document document = collection.find(eq(ID_FIELD, objectId)).first();    if (document != null) {      return new Product(          document.getObjectId(ID_FIELD).toString(),          document.getString(NAME_FIELD),          document.getDouble(PRICE_FIELD),          document.getString(DESCRIPTION_FIELD),          document.getString(IMAGE_URI_FIELD));    }    return null;  }  public List&lt;Product&gt; findAllProducts() {    List&lt;Product&gt; products = new ArrayList&lt;&gt;();    for (Document doc : collection.find()) {      products.add(          new Product(              doc.getObjectId(ID_FIELD).toString(),              doc.getString(NAME_FIELD),              doc.getDouble(PRICE_FIELD),              doc.getString(DESCRIPTION_FIELD),              doc.getString(IMAGE_URI_FIELD)));    }    return products;  }  public void updateProduct(Product product) {    Document updatedDoc =        new Document(NAME_FIELD, product.getName())            .append(PRICE_FIELD, product.getPrice())            .append(DESCRIPTION_FIELD, product.getDescription())            .append(IMAGE_URI_FIELD, product.getImageUri());    collection.updateOne(eq(ID_FIELD, product.getId()), new Document(\"$set\", updatedDoc));  }  public void deleteProduct(String id) {    collection.deleteOne(eq(ID_FIELD, id));  }}Por fim, podemos ver a aplicação com esses métodos em atividade.import org.danielmesquita.dbconfig.DB;import org.danielmesquita.entities.Product;import org.danielmesquita.repository.ProductRepository;public class Application {  public static void main(String[] args) {    ProductRepository repository = new ProductRepository();    Product product = new Product(null, \"Celular\", 3000.00, \"Iphone 13\", \"iphone.jpg\");    repository.insertProduct(product);    System.out.println(\"Product inserted successfully\");    Product foundProduct = repository.findProductById(\"66d902926170417768c84cfd\");    System.out.println(\"Product found: \" + foundProduct.getName());    foundProduct.setPrice(2300.00);    repository.updateProduct(foundProduct);    System.out.println(\"Product price updated to: \" + foundProduct.getPrice());    repository.deleteProduct(foundProduct.getId());    System.out.println(\"Product deleted\");    DB.closeConnection();  }}Aqui ativamos os métodos principais de edição do banco em um modelo CRUD (create, read, update, delete). E fim. Entregamos uma aplicação que pode servir de base local pra você ir aprimorando para criar coisas mais refinadas.Aqui estão os repositórios do Github com os códigos dessa série de postagem.Java com PostgreSQLJava com MongoDBEu pensei em encerrar esta série aqui. Mas acho que tem coisas importantes a explorar que vou tratar talvez em mais 1 ou 2 posts:  MongoDB rodando no Docker ao invés de instalado, é bem mais simples (e o que é Docker);  SQL e NoSQL com Java e Springboot, para mostrar a diferença de interação com um banco de dados.Abraço!"
  },
  
  {
    "title": "Conectando bancos de dados locais - Parte III",
    "url": "/posts/database-local-connection-pt-III/",
    "categories": "Programação, Banco de dados",
    "tags": "programação, mongodb, banco de dados, nosql",
    "date": "2024-09-04 23:00:00 -0300",
    





    
    "snippet": "Já falamos sobre como configurar localmente o banco sql postgres e como conectar uma aplicação Java a ele. Caso não tenha visto: primeira parte e segunda parte, se for do seu interesse.Hoje vou fal...",
    "content": "Já falamos sobre como configurar localmente o banco sql postgres e como conectar uma aplicação Java a ele. Caso não tenha visto: primeira parte e segunda parte, se for do seu interesse.Hoje vou falar de como configurar um banco NoSQL localmente, para isso vou utilizar o MongoDB Community Edition. Eu ia colocar no post como instalar, mas lendo a documentação, acho que ela está bem auto-explicativa. Inclusive enfrentei problemas pra instalar no Ubuntu e resolvi usando a própria documentação. Seguem abaixo os links:Link para baixarInstalaçao no LinuxTroubleshoot Ubuntu Installation.Instalação no WindowsInstalação no MacDepois, é importante instalar o Mongo Compass, que fornece uma GUI para manusear as coleções na sua máquina. Ele tem essa carinha aqui:O banco NoSQL é um pouco mais amigável que um SQL pra você lidar com ele. Se você acessar um postgres ou um dbeaver da vida, é bem mais complexo, porque tem uma série de relações e particularidades do SQL que o NoSQL não tem.Ele vem por padrão na porta 27017. Só mude se fizer questão. Uma vez conectado, ele vem assim:Aqui você pode criar seus bancos de dados e coleções que pode necessitar na sua aplicação. Mas não vamos criar schemas ou objetos por aqui. Vamos fazer via aplicação Java.Primeiro, no pom.xml você vai precisar das seguintes dependências:    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.mongodb&lt;/groupId&gt;            &lt;artifactId&gt;mongodb-driver-sync&lt;/artifactId&gt;            &lt;version&gt;5.1.1&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;javax.validation&lt;/groupId&gt;            &lt;artifactId&gt;validation-api&lt;/artifactId&gt;            &lt;version&gt;2.0.1.Final&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.slf4j&lt;/groupId&gt;            &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;            &lt;version&gt;2.0.9&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.slf4j&lt;/groupId&gt;            &lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt;            &lt;version&gt;2.0.9&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;Depois, assim como para o postgres, precisamos de um arquivo .properties para definir algumas propriedades do banco de dados:mongodb.uri=mongodb://localhost:27017mongodb.database=delivery-managerCom isso no ponto importante mandar um mvn clean install pra instalar as dependências e podermos seguir.Agora vamos montar a conexão com o banco. Vamos seguir um padrão semelhante da configuração do postgres, criando uma classe específica para gerenciar a conexão com o MongoDB.No código abaixo eu utilizo o API do MongoDB para o Java (mongo-java-driver) carregando as configurações do banco a partir do arquivo db.properties.Eu declaro um atributo estático MongoClient que é uma interface da API do MongoDB para conectar com o banco de dados.Depois crio o método getConnection(), responsável por retornar uma conexão ativa com o Mongo. Primeiro ele carrega as definições do banco do arquivo db.properties chamando o método loadProperties(). Depois ele verifica se mongoClient é null, ou seja, se tem alguma conexão ativa com o banco de dados, se não tiver, ele abre uma nova conexão utilizando o uri do banco local. Por último, ele obtém o nome do banco a partir das properties e retorna a instância de MongoDatabase correspondente ao nosso banco.Além disso crio o método closeConnection(), necessário para encerrar a conexão com o banco.E também o método loadProperties(), que carrega as informações do arquivo db.properties.import com.mongodb.client.MongoClient;import com.mongodb.client.MongoClients;import com.mongodb.client.MongoDatabase;import java.io.FileInputStream;import java.io.IOException;import java.util.Properties;public class DB {  private static MongoClient mongoClient;  public static MongoDatabase getConnection() {    Properties props = loadProperties();    if (mongoClient == null) {      String uri = props.getProperty(\"mongodb.uri\");      mongoClient = MongoClients.create(uri);    }    String databaseName = props.getProperty(\"mongodb.database\");    return mongoClient.getDatabase(databaseName);  }  public static void closeConnection() {    if (mongoClient != null) {      mongoClient.close();    }  }  private static Properties loadProperties() {    try (FileInputStream fs = new FileInputStream(\"src/main/resources/db.properties\")) {      Properties props = new Properties();      props.load(fs);      return props;    } catch (IOException e) {      throw new DbException(e.getMessage());    }  }}A parte de configuração do MongoDB é relativamente mais fácil que a do PostgreSQL.Depois, vamos criar a nossa entidade Product com o schema que vai ser utilizado na collection.import javax.validation.constraints.NotNull;import javax.validation.constraints.Size;public class Product {  private String id;  @NotNull(message = \"Product name is required\")  private String name;  @NotNull(message = \"Product price is required\")  private Double price;  @NotNull(message = \"Product description is required\")  @Size(min = 10, message = \"Product description requires 10 characters at least\")  private String description;  private String imageUri;  public Product() {}  public Product(String id, String name, Double price, String description, String imageUri) {    this.id = id;    this.name = name;    this.price = price;    this.description = description;    this.imageUri = imageUri;  }  public String getId() {    return id;  }  public void setId(String id) {    this.id = id;  }  public String getName() {    return name;  }  public void setName(String name) {    this.name = name;  }  public Double getPrice() {    return price;  }  public void setPrice(Double price) {    this.price = price;  }  public String getDescription() {    return description;  }  public void setDescription(String description) {    this.description = description;  }  public String getImageUri() {    return imageUri;  }  public void setImageUri(String imageUri) {    this.imageUri = imageUri;  }  public boolean validateId(String id) {    return id != null &amp;&amp; !id.isEmpty();  }}Eu incluí o método validateId caso precise verificar se aquele id daquele objeto é válido para inserir no banco só por precaução.Bom, o tempo foi corrido, já finalizei o código todo, mas ainda não tive tempo de produzir uma explicação adequada. Vou encerrar essa postagem por aqui para que possa dar tempo de ver a instalação e caso tenha alguma dúvida, só me procurar.Abraço!"
  },
  
  {
    "title": "Conectando bancos de dados locais - Parte II",
    "url": "/posts/database-local-connection-pt-II/",
    "categories": "Programação, Banco de dados",
    "tags": "programação, postgres, banco de dados, sql",
    "date": "2024-09-02 06:10:00 -0300",
    





    
    "snippet": "Agora que já foi possível conectar o banco postegres usando o JDBC*, podemos seguir em frente e criar os métodos que vão interagir com o banco de dados. Caso não tenha visto a primeira parte, é fun...",
    "content": "Agora que já foi possível conectar o banco postegres usando o JDBC*, podemos seguir em frente e criar os métodos que vão interagir com o banco de dados. Caso não tenha visto a primeira parte, é fundamental que veja.Primeiro, precisamos alimentar as tabelas com algum dado. Isso não vai ser feito via mágica, vamos usar queries SQL mesmo. Na parte I, criamos a tabela product. Agora vamos criar uma tabela order e seu alter incluir dados nela. Indo pelo pgAdmin, utilizando o Queries Tool, podemos incluir algo do tipo:INSERT INTO tb_product (name, price, image_Uri, description) VALUES ('Smartphone Samsung Galaxy', 1200.0, 'https://teste.com/images/1.png', 'Smartphone samsung com SO Android e acesso a 5G'),('Notebook Lenovo', 2500.0, 'https://teste.com/images/2.png', 'Notebook 16GB RAM, Intel i5'),('Earbuds Xiaomi', 400.0, 'https://teste.com/images/3.png', 'Fone de ouvido intra auricular');Feito isso, agora temos uma tabela com dados para podermos explorar.Voltando agora para nossa aplicação, temos que criar a entidade que vai se relacionar com a tabela que criamos:package org.danielmesquita.entities;public class Product {  private long id;  private String name;  private Double price;  private String description;  private String imageUri;  public Product() {}  public Product(long id, String name, Double price, String description, String imageUri) {    this.id = id;    this.name = name;    this.price = price;    this.description = description;    this.imageUri = imageUri;  }  public long getId() {    return id;  }  public void setId(long id) {    this.id = id;  }  public String getName() {    return name;  }  public void setName(String name) {    this.name = name;  }  public Double getPrice() {    return price;  }  public void setPrice(Double price) {    this.price = price;  }  public String getDescription() {    return description;  }  public void setDescription(String description) {    this.description = description;  }  public String getImageUri() {    return imageUri;  }  public void setImageUri(String imageUri) {    this.imageUri = imageUri;  }  @Override  public String toString() {    return \"Product{\" +            \"id=\" + id +            \", name='\" + name + '\\'' +            \", price=\" + price +            \", description='\" + description + '\\'' +            \", imageUri='\" + imageUri + '\\'' +            '}';  }}Com a entidade criada e o banco populado e conectado, agora dá pra brincar com os dados. Você pode passar as queries SQL que vamos utilizar todas para uma classe a parte para critérios de organização:package org.danielmesquita.constants;public class QueriesSQL {  public static final String FIND_ALL_PRODUCTS = \"SELECT * FROM products\";  public static final String INSERT_PRODUCTS =      \"INSERT INTO tb_product (name, price, image_uri, description) VALUES (?, ?, ?, ?)\";  public static final String DELETE_PRODUCT = \"DELETE FROM tb_product WHERE id = ?\";  public static final String UPDATE_PRODUCT =      \"UPDATE tb_product SET name = ?, price = ?, image_uri = ?, description = ? WHERE id = ?\";}E por fim, temos os métodos que irão interagir com o nosso banco de dados:  private static Product instantiateProduct(ResultSet resultSet) throws SQLException {    Product product = new Product();    product.setId(        resultSet.getLong(            \"product_id\")); // product_id instead of id to avoid conflict with Order id    product.setName(resultSet.getString(\"name\"));    product.setPrice(resultSet.getDouble(\"price\"));    product.setDescription(resultSet.getString(\"description\"));    product.setImageUri(resultSet.getString(\"image_uri\"));    return product;  }    public void insertProduct(Product product) {    try (Connection connection = DB.getConnection();        PreparedStatement preparedStatement =            connection.prepareStatement(QueriesSQL.INSERT_PRODUCTS, Statement.RETURN_GENERATED_KEYS)) {      preparedStatement.setString(1, product.getName());      preparedStatement.setDouble(2, product.getPrice());      preparedStatement.setString(3, product.getDescription());      preparedStatement.setString(4, product.getImageUri());      int rowsAffected = preparedStatement.executeUpdate();      if (rowsAffected &gt; 0) {        try (ResultSet resultSet = preparedStatement.getGeneratedKeys()) {          if (resultSet.next()) {            product.setId(resultSet.getLong(1)); // Set the generated ID back to the product object          }        }      }    } catch (SQLException e) {      throw new DbException(e.getMessage());    }  }  public void deleteProductById(long id) {    try (Connection connection = DB.getConnection();        PreparedStatement preparedStatement = connection.prepareStatement(QueriesSQL.DELETE_PRODUCT)) {      preparedStatement.setLong(1, id);      preparedStatement.executeUpdate();    } catch (SQLException e) {      throw new DbException(e.getMessage());    }  }  public void updateProduct(Product product) {    try (Connection connection = DB.getConnection();        PreparedStatement preparedStatement = connection.prepareStatement(QueriesSQL.UPDATE_PRODUCT)) {      preparedStatement.setString(1, product.getName());      preparedStatement.setDouble(2, product.getPrice());      preparedStatement.setString(3, product.getDescription());      preparedStatement.setString(4, product.getImageUri());      preparedStatement.setLong(5, product.getId());      int rowsAffected = preparedStatement.executeUpdate();      if (rowsAffected == 0) {        throw new DbException(\"No product found with the given ID: \" + product.getId());      }    } catch (SQLException e) {      throw new DbException(e.getMessage());    }  }E agora no método main você pode testar o seu banco de dados postgres. Se quiser melhorar, pode separar os métodos nas suas responsabilidades em packages e classes específicas para aprimorar.package org.danielmesquita;import java.sql.*;import java.util.HashMap;import java.util.Map;import org.danielmesquita.constants.QueriesSQL;import org.danielmesquita.dbconfig.DB;import org.danielmesquita.dbconfig.DbException;import org.danielmesquita.entities.Product;public class Application {  public static void main(String[] args) throws SQLException {    Connection connection = DB.getConnection();    Statement statement = connection.createStatement();    ResultSet resultSet = statement.executeQuery(QueriesSQL.FIND_ALL_PRODUCTS);    Map&lt;Long, Product&gt; productMap = new HashMap&lt;&gt;();    while (resultSet.next()) {      Long productId = resultSet.getLong(\"product_id\");      if (productMap.get(productId) == null) {        Product product = instantiateProduct(resultSet);        productMap.put(productId, product);      }      System.out.println(\"Product: \" + productMap.get(productId));    }    Product productToUpdate = new Product();    productToUpdate.setId(1L);  // Supondo que você quer atualizar o produto com ID 1    productToUpdate.setName(\"Samsung Galaxy S21\");    productToUpdate.setPrice(2000.0);    productToUpdate.setDescription(\"The best Android phone ever\");    productToUpdate.setImageUri(\"https://www.samsung.com/samsung-galaxy-s21.jpg\");    updateProduct(productToUpdate);    System.out.println(\"Product updated: \" + productToUpdate);    Product newProduct = new Product();    newProduct.setName(\"Iphone 13\");    newProduct.setPrice(3000.0);    newProduct.setDescription(\"The best iPhone ever\");    newProduct.setImageUri(\"https://apple.com/iphone/4.png\");    insertProduct(newProduct);    System.out.println(\"New product inserted: \" + newProduct);    deleteProductById(newProduct.getId());    System.out.println(\"Product deleted: \" + newProduct.getId());  }  private static Product instantiateProduct(ResultSet resultSet) throws SQLException {    Product product = new Product();    product.setId(        resultSet.getLong(            \"product_id\"));    product.setName(resultSet.getString(\"name\"));    product.setPrice(resultSet.getDouble(\"price\"));    product.setDescription(resultSet.getString(\"description\"));    product.setImageUri(resultSet.getString(\"image_uri\"));    return product;  }  public static void insertProduct(Product product) {    try (Connection connection = DB.getConnection();        PreparedStatement preparedStatement =            connection.prepareStatement(QueriesSQL.INSERT_PRODUCTS, Statement.RETURN_GENERATED_KEYS)) {      preparedStatement.setString(1, product.getName());      preparedStatement.setDouble(2, product.getPrice());      preparedStatement.setString(3, product.getDescription());      preparedStatement.setString(4, product.getImageUri());      int rowsAffected = preparedStatement.executeUpdate();      if (rowsAffected &gt; 0) {        try (ResultSet resultSet = preparedStatement.getGeneratedKeys()) {          if (resultSet.next()) {            product.setId(resultSet.getLong(1));          }        }      }    } catch (SQLException e) {      throw new DbException(e.getMessage());    }  }  public static void deleteProductById(long id) {    try (Connection connection = DB.getConnection();        PreparedStatement preparedStatement = connection.prepareStatement(QueriesSQL.DELETE_PRODUCT)) {      preparedStatement.setLong(1, id);      preparedStatement.executeUpdate();    } catch (SQLException e) {      throw new DbException(e.getMessage());    }  }  public static void updateProduct(Product product) {    try (Connection connection = DB.getConnection();        PreparedStatement preparedStatement = connection.prepareStatement(QueriesSQL.UPDATE_PRODUCT)) {      preparedStatement.setString(1, product.getName());      preparedStatement.setDouble(2, product.getPrice());      preparedStatement.setString(3, product.getDescription());      preparedStatement.setString(4, product.getImageUri());      preparedStatement.setLong(5, product.getId());      int rowsAffected = preparedStatement.executeUpdate();      if (rowsAffected == 0) {        throw new DbException(\"No product found with the given ID: \" + product.getId());      }    } catch (SQLException e) {      throw new DbException(e.getMessage());    }  }}Esse é um exemplo de um CRUD simples utilizando um banco SQL configurado utilizando postgres e o pgAdmin para executar as queries necessárias e visualizar as tabelas. Utilizando o Spring seria muito mais simples devido as funcionalidades que o framework disponibiliza, mas não é o foco deste conteúdo. Aqui é mais pra mostrar como utilizar os bancos no ambiente local.Em breve eu vou trazer aqui a configuração do MongoDB que é um banco NoSQL e como utilizar o Java para manipular os dados.Abraços!*JDBC (Java Database Connectivity) é uma API (Application Programming Interface) do Java que permite que aplicativos Java se conectem a bancos de dados, enviem consultas SQL e manipulem dados armazenados neles. Basicamente, o JDBC atua como uma ponte entre o código Java e o banco de dados, permitindo que você execute operações como inserir, atualizar, excluir e consultar dados.Componentes Principais do JDBCDriver JDBC: Um driver JDBC é uma implementação específica da API JDBC para um banco de dados particular (como PostgreSQL, MySQL, Oracle, etc.). Ele traduz as chamadas JDBC em comandos específicos do banco de dados.Connection: Representa uma conexão com um banco de dados. Você usa o Connection para interagir com o banco, abrir transações e criar Statements ou PreparedStatements.Statement e PreparedStatement: Objetos usados para executar consultas SQL. Statement é usado para consultas simples, enquanto PreparedStatement permite consultas parametrizadas, o que é mais seguro contra injeções de SQL.ResultSet: Um conjunto de resultados de uma consulta SQL, retornando dados do banco de dados em forma de tabela. O ResultSet é iterado para acessar os dados linha por linha.SQLException: Exceções lançadas quando ocorrem erros durante a interação com o banco de dados.Como o JDBC FuncionaCarregar o Driver JDBC: Carregar a classe do driver para o banco de dados que você deseja usar.Estabelecer uma Conexão: Usar o DriverManager para estabelecer uma conexão com o banco de dados, fornecendo a URL do banco, nome de usuário e senha.Executar Consultas: Usar objetos Statement ou PreparedStatement para executar instruções SQL no banco de dados.Processar os Resultados: Se a consulta retornar dados, você processa os resultados usando o ResultSet.Fechar a Conexão: Após completar as operações, a conexão com o banco de dados deve ser fechada para liberar recursos."
  },
  
  {
    "title": "Conectando bancos de dados locais - Parte I",
    "url": "/posts/database-local-connection-pt-I/",
    "categories": "Programação, Banco de dados",
    "tags": "programação, postgres, banco de dados, sql",
    "date": "2024-09-01 08:10:00 -0300",
    





    
    "snippet": "Uma coisa que todo programador ou estudante back-end precisa ter para fazer qualquer coisa útil, é um banco de dados rodando. Afinal de contas, tudo é CRUD (polêmico) e não se faz um sem um banco d...",
    "content": "Uma coisa que todo programador ou estudante back-end precisa ter para fazer qualquer coisa útil, é um banco de dados rodando. Afinal de contas, tudo é CRUD (polêmico) e não se faz um sem um banco de dados.Uma coisa importante é que existem alguns passos a se configurar um banco de dados local na sua máquina para poder rodar sua aplicação e manusear dados.Eu não vou me aprofundar aqui sobre as diferenças de SQL e NoSQL, tem bastante material por aí, senta a bunda na cadeira e vai estudar. Aqui eu vou falar sobre as diferenças de conexões, como implementar e o que precisa escrever de código. Para este post eu vou usar Java numa abordagem Vanilla, ou seja, sem framework. E para lidar com bancos de dados eu vou usar o Postgres para SQL e MongoDB para NoSQL.Vai ser uma série de 4 posts, este primeiro vou mostrar a configuração do postgres, no segundo a criação de entidades e tabelas e suas relações, no terceiro configuro o MongoDB e no quarto foco em interação de entidades, tabelas e suas relações em um banco NoSQL.Primeiro, para poder utilizar qualquer banco de dados, você precisa instalar e botar pra rodar na sua máquina. No Windows é bem intuitivo porque tudo é instalado via aquivo .exe. No Linux precisamos rodar alguns comandos no terminal pra poder funcionar tudo direitinho. Isso não quer dizer que o ambiente do Windows é melhor pra desenvolver, não se iluda.Presumindo que você já tem uma jdk instalada, pelo menos da 11 pra frente, vamos configurar as coisas. No windows, só ir no site e instalar e no Linux vou mostrar um passo a passo básico aqui.Primeiro você atualiza a lista de packages e então instala o postgres:sudo apt updatesudo apt install postgresql postgresql-contribDepois você precisa iniciar o serviço:sudo systemctl start postgresqlSe quiser que o postgres já inicie quando a máquina ligar:sudo systemctl enable postgresqlPostgreSQL cria um user por default chamado de postgres, então mude para esse usuário:sudo -i -u postgresAcesse o CLI do PostgreSQL:psqlRecomendo mudar a senha pois você vai precisar dela:ALTER USER postgres PASSWORD 'nova_senha';Saia do prompt do postgres:\\qSaia do usuário do postgres:exitPronto, você está com o postgres instalado e pronto pra usar. Para administrar o banco de dados, eu utilizo o pgAdmin4, que você pode usar tanto a aplicação web quanto a versão desktop. Eu utilizo a desktop. Segue o roteiro:Adicione o repositório do pgAdmin:curl https://www.pgadmin.org/static/packages_pgadmin_org.pub | sudo apt-key addsudo sh -c 'echo \"deb https://ftp.postgresql.org/pub/pgadmin/pgadmin4/apt/focal pgadmin4 main\" &gt; /etc/apt/sources.list.d/pgadmin4.list'Atualize a list de packages e instale o pgAdmin:sudo apt updatesudo apt install pgadmin4Na sua instalação pode querer definir se quer a versão desktop pgadmin4-desktop ou o webapp pgadmin4-web. Se preferir usar o web app, recomendo o seguinte passo:sudo /usr/pgadmin4/bin/setup-web.shAgora vamos ao que interessa que é preparar seu banco de dados para ser utilizado. Abrindo o pgAdmin desktop, você clica com o botão direito em Server e vai Register -&gt; Server…Aí você vai dar de cara com General Tab, um menu que pede o name do server, aqui é livre, vamos supor “PostgreSQL Server” e depois você vai em Connection Tabe, coloa no host name localhost, uma vez que você vai rodar local neste caso, a porta padrão do postgres é 5432 e geralmente já vem por default, o usuário postgres que configuramos antes e a senha que você escolheu. Vai de Save e seu novo Server vai estar lá.Depois no server que você criou, pode clicar com o botão direito para criar um database com o nome que você achar melhor. Seu banco de dados não vai ter nenhuma tabela. Então você vai em Schemas -&gt; Tables e clica com o botão direito, lá você pode usar o menu do pgAdmin ou criar as tabelas via query do SQL selecionando Query Tool. Um exemplo de query SQL para você criar uma tabela:create table tb_order_product (    order_id int8 not null,     product_id int8 not null,     primary key (order_id, product_id));Com o postgres configurado e rodando, precisamos agora criar a conexão com a aplicação. Menos palavras e mais código. Segue a implementação que usei no meu caso. Primeiro, para rodar local, você precisa de um arquivo db.properties:dbuser=postgresdbpassword=sua_senhadburl=jdbc:postgresql://localhost:5432/seu_banco_de_dadosuseSSL=false  Desativação do SSL: Quando você define useSSL=false, está explicitamente informando ao driver JDBC que ele não deve usar SSL para a conexão com o banco de dados. Isso é útil em ambientes onde a comunicação SSL não é necessária, como em ambientes de desenvolvimento local, onde a segurança da comunicação entre o aplicativo e o banco de dados pode não ser uma prioridade tão alta.Depois, é necessário criar a classe que ativa a conexão com o banco de dados. Nesta classe eu utilizei 3 métodos: um para criar a conexão com o banco, um para encerrar a conexão e outro que utiliza a classe FileInputStream para acessar o arquivo db.properties e coletar os dados.import java.io.FileInputStream;import java.io.IOException;import java.sql.Connection;import java.sql.DriverManager;import java.sql.SQLException;import java.util.Properties;public class DB {  private static Connection conn = null;  public static Connection getConnection() {    if (conn == null) {      try {        Properties props = loadProperties();        String url = props.getProperty(\"dburl\");        String user = props.getProperty(\"dbuser\");        String password = props.getProperty(\"dbpassword\");        conn = DriverManager.getConnection(url, user, password);      } catch (SQLException e) {        throw new DbException(e.getMessage());      }    }    return conn;  }  public static void closeConnection() {    if (conn != null) {      try {        conn.close();      } catch (SQLException e) {        throw new DbException(e.getMessage());      }    }  }  private static Properties loadProperties() {    try (FileInputStream fs = new FileInputStream(\"db.properties\")) {      Properties props = new Properties();      props.load(fs);      return props;    } catch (IOException e) {      throw new DbException(e.getMessage());    }  }}Além disso, criei uma classe DbException que extende RuntimeException para lidar e comunicar os erros que possam acontecer na conexão:public class DbException extends RuntimeException {  private static final long serialVersionUID = 1L;  public DbException(String msg) {    super(msg);  }}É isso, o banco está configurado para uso. No próximo post trago a implementação das entidades e tabelas e como realizar o CRUD propriamente dito.Abraços!"
  },
  
  {
    "title": "Faça seu próprio código",
    "url": "/posts/make-your-own-code/",
    "categories": "Programação, Estudos",
    "tags": "programação, código, estudos, node, javascript",
    "date": "2024-08-26 00:10:00 -0300",
    





    
    "snippet": "No começo dos meus estudos em programação, eu fui um dos vários casos que acompanhou cursos onde o instrutor vai escrevendo o código e ensinando as coisas enquanto o aluno vai replicando.Eu acho qu...",
    "content": "No começo dos meus estudos em programação, eu fui um dos vários casos que acompanhou cursos onde o instrutor vai escrevendo o código e ensinando as coisas enquanto o aluno vai replicando.Eu acho que esse tipo de metodologia tem seu valor, mas depende muito do aluno.Passei quase um ano sem acessar nenhum material e estudar nesse formato. Atualmente estou em uma disciplina na faculdade que o projeto final consiste em uma aplicação de gestão de consultas médicas, envolvendo entidades médico, paciente, consulta e receita. Nada muito complexo. Back-end em Node. Nada muito complexo.E por não parecer complexo, o aluno pode cair na cilada de sair só copiando código do professor, sem ir colocando sua marca ali. Depois de tanto tempo sem acompanhar um material nesse formato, hoje eu me sinto extremamente incomodado em ficar assistindo alguém escrever código. Vou dar um exemplo pra explicar o que eu tenho feito. O print abaixo é do código original da disciplina, da entidade Appointment:import { mongoose } from \"mongoose\";import Pacient from \"./Pacient.js\";import Doctor from \"./Doctor.js\";const Schema = mongoose.Schema;const appointmentSchema = new Schema ({    date: {        type: Date,        required: [true, 'Appointment Date is required.']    },    doctorId: {        type: String,        required: [true, 'DoctorId is required.'],        validate: {            validator: function (v){                const id = new mongoose.Types.ObjectId(v); // convertendo uma string em objeto ID para ser encontrado no banco                return Doctor.exists({_id: id});            },            message: props =&gt;             `DoctorID ${props.value} not found.`         }    },    pacientId: {        type: String,        required: [true, 'PacientId is required.'],        validate: {            validator: function (v){                const id = new mongoose.Types.ObjectId(v); // convertendo uma string em objeto ID para ser encontrado no banco                return Pacient.exists({_id: id});            },            message: props =&gt;             `PacientID ${props.value} not found.`         }    },    createdAt: {        type: Date,        default: Date.now    }});const appointment = mongoose.model('Appointment', appointmentSchema);export default appointment;Você pode notar que existe uma repetição de código para realizar a validação de campos utilizam a mesma lógica. Eu sou muito crítico com código repetido, então criei um utils para validações e limpei um pouco a entidade:import mongoose from \"mongoose\";import Doctor from \"./Doctor.js\";import Pacient from \"./Pacient.js\";import { validateId, idValidationMessage } from './utils/validators.js';const Schema = mongoose.Schema;const appointmentSchema = new Schema ({    date: {        type: Date,        required: [true, 'Appointment date is required'],    },    doctorId: {        type: String,        required: [true, 'Doctor ID is required'],        validate: {            validator: function (v) {                return validateId(v, mongoose, Doctor);            },            message: idValidationMessage,        }    },    pacientId: {        type: String,        required: [true, 'Pacient ID is required'],        validate: {            validator: function (v) {                return validateId(v, mongoose, Pacient);            },            message: idValidationMessage,        }    },    createdAt: {        type: Date,        default: Date.now,    }});const appointment = mongoose.model('Appointment', appointmentSchema);export default appointment;Outra mudança que eu tive que fazer para melhorar a qualidade do código foi nos repositories e controllers. Inicialmente o repository para incluir um novo item no banco, precisava receber um objeto com todos os campos daquela entidade para fazer a lógica de inclusão. Isso não é o errado, o que fica estranho é ter isso declarado diretamente em todo o código, como abaixo:import Doctor from \"../models/Doctor.js\"const getAllDoctors = async () =&gt; {    try{        return await Doctor.find();    }catch(error){        throw new Error(error);    }}const getDoctor = async (id) =&gt; {    try{        return await Doctor.findById(id);    }catch(error){        throw new Error(error);    }}const saveDoctor = async ({ name, login, password, medicalSpecialty, medicalRegistration, email, phone }) =&gt; {    try{        const doctor = new Doctor({ name, login, password, medicalSpecialty, medicalRegistration, email, phone });        return await doctor.save();    }catch(error){        throw new Error(error);    }}const updateDoctor = async (id, { name, login, password, medicalSpecialty, medicalRegistration, email, phone }) =&gt; {    try{        return await Doctor.findByIdAndUpdate(id, { name, login, password, medicalSpecialty, medicalRegistration, email, phone }, { new: true });    }catch(error){        throw new Error(error);    }}const deleteDoctor = async (id) =&gt; {    try{        return await Doctor.findByIdAndDelete(id);    }catch(error){        throw new Error(error);    }}// loginconst getDoctorByLogin = async (login) =&gt; {    try {        return await Doctor.findOne({\"login\": login});    } catch (error) {        throw new Error(error);    }}const doctorRepository = {    getAllDoctors,    getDoctor,    saveDoctor,    updateDoctor,    deleteDoctor,    getDoctorByLogin}export default doctorRepository;Eu também “escondi” toda a lógica de construção do objeto que será enviado para o banco em uma função separada. Assim o repository fica mais “limpo” e não precisa ter a mesma lógica de construção de objeto para todos os campos.import Doctor from \"../models/Doctor.js\"import { buildDoctorData } from \"../utils/BuildDataUtils.js\"const getAllDoctors = async () =&gt; {    return await Doctor.find();}const getDoctor = async (id) =&gt; {    try {        return await Doctor.findById(id);    } catch (error) {        throw new Error(error);    }}const saveDoctor = async (data) =&gt; {    try {        const doctor = new Doctor(buildDoctorData(data));        return await doctor.save();    } catch (error) {        throw new Error(error);    }}const updateDoctor = async (id, data) =&gt; {    try{        return await Doctor.findByIdAndUpdate(id, buildDoctorData(data), { new: true });    }catch(error){        throw new Error(error);    }}const deleteDoctor = async (id) =&gt; {    try {        return await Doctor.findByIdAndUpdate(id);    } catch (error) {        throw new Error(error);    }}const getDoctorByLogin = async (login) =&gt; {    try {        return await Doctor.findOne({\"login\": login});    } catch (error) {        throw new Error(error);    }}const doctorRepository = {    getAllDoctors,    getDoctor,    saveDoctor,    updateDoctor,    deleteDoctor,    getDoctorByLogin}export default doctorRepository;Uma outra edição relevante que fiz foi nos controllers. Todos utilizam o router do express para fazer as chamadas. Todos os controllers tem basicamente as mesmas rotas apra cada entidade. O original não incluía casos para entidades não encontradas no banco, assim como todos as rotas utilizavam um blco try/catch para capturar e passar os erros adiante:import express from \"express\";import AppointmentService from \"../services/AppointmentService.js\";let router = express.Router();router.get('/appointments', async(req, res) =&gt; {    try {        const appointments = await AppointmentService.getAllAppointments();        res.send(appointments);    } catch (error) {        console.log(error);        res.status(500).send(error);    }});router.get('/getAppointment/:id', async(req, res) =&gt; {    const {id} = req.params;    try {        const appointment = await AppointmentService.getAppointment(id);        res.send(appointment);    } catch (error) {        console.log(error);        res.status(500).send(error);    }});router.post('/postAppointment', async(req, res) =&gt; {    const {date, doctorId, pacientId} = req.body;    try {        const appointment = await AppointmentService.saveAppointment({date, doctorId, pacientId});        res.send(appointment);    } catch (error) {        console.log(error);        res.status(500).send(error);    }});router.put('/appointments/:id', async(req, res) =&gt; {    const {id} = req.params;    const {date, doctorId, pacientId} = req.body;    try {        const appointment = await AppointmentService.updateAppointment(id, {date, doctorId, pacientId});        res.send(appointment);    } catch (error) {        console.log(error);        res.status(500).send(error);    }});router.delete('/appointments/:id', async(req, res) =&gt; {    const {id} = req.params;    try {        const appointment = await AppointmentService.deleteAppointment(id);        res.send(appointment);    } catch (error) {        console.log(error);        res.status(500).send(error);    }});router.put('/reschedule/:id', async(req, res) =&gt; {    const {id} = req.params;    const {date} = req.body;    try {        let appointment = await AppointmentService.getAppointment(id);        appointment.date = date;        appointment = await AppointmentService.updateAppointment(id, {date});        res.send(appointment);    } catch (error) {        console.log(error);        res.status(500).send(error);    }});export default router;Então criei um asyncHandler para esse cara:export const asyncHandler = fn =&gt; (req, res, next) =&gt;    Promise.resolve(fn(req, res, next)).catch(next);O que eu decidi fazer foi utilizar um middleware de utilitário do express para lidar com funções assíncronas de maneira mais elegante, automatizando os tratamentos das rotas:1 - O “fn” é uma função assíncrona que eu desejo executar, com a assinatura (req, res, next) que pode retornar uma Promise;2 - O asyncHandler retorna uma nova função rque recebe os mesmos parâmetros que “fn”;3 - Promise.resolve() é utilizado para que garantir que o retorno de “fn” seja tratado como uma promessa, mesmo se “fn” não retornar uma promise explícita (como uma função síncrona, por exemplo);4 - No caso do “.catch(next)” se a promessa retornada por “fn” for rejeitada (ou seja, se um erro ocorrer dentro de “fn”), o .catch(next) captura esse erro e o passa para o middleware de tratamento de erros do Express (chamando a função next com o erro como argumento).import express from \"express\";import AppointmentService from \"../services/AppointmentService.js\";import { buildAppointmentData } from \"../utils/BuildDataUtils.js\";import { asyncHandler } from \"../utils/AsyncHandler.js\";import { errorHandler } from \"../utils/ErrorHandler.js\";let router = express.Router();const notFoundErrorMessage = 'Appointment not found';router.get('/appointments', asyncHandler(async (req, res) =&gt; {    const appointments = await AppointmentService.getAllAppointments();    res.json(appointments);}));router.get('/appointments/getAppointment/:id', asyncHandler(async (req, res) =&gt; {    const { id } = req.params;    const appointment = await AppointmentService.getAppointment(id);    if (appointment) {        res.json(appointment);    } else {        res.status(404).json({ error: notFoundErrorMessage });    }}));router.post('/appointments/createAppointment', asyncHandler(async (req, res) =&gt; {    const data = req.body;    const appointment = await AppointmentService.saveAppointment(buildAppointmentData(data));    res.status(201).json(appointment);}));router.put('/appointments/updateAppointment/:id', asyncHandler(async (req, res) =&gt; {    const { id } = req.params;    const data = req.body;    const updatedAppointment = await AppointmentService.updateAppointment(id, buildAppointmentData(data));    if (updatedAppointment) {        res.json(updatedAppointment);    } else {        res.status(404).json({ error: notFoundErrorMessage });    }}));router.delete('/appointments/deleteAppointment/:id', asyncHandler(async (req, res) =&gt; {    const { id } = req.params;    const deletedAppointment = await AppointmentService.deleteAppointment(id);    if (deletedAppointment) {        res.json(deletedAppointment);    } else {        res.status(404).json({ error: notFoundErrorMessage });    }}));router.put('/appointments/rescheduleAppointment/:id', async(req, res) =&gt; {    const {id} = req.params;    const {date} = req.body;    let appointment = await AppointmentService.getAppointment(id);    if (!appointment) {        return res.status(404).json({ error: notFoundErrorMessage })    }    const rescheduleAppointment = await AppointmentService.updateAppointment(id, {date});    res.json(rescheduleAppointment);});router.use(errorHandler);export default router;Neste caso o asyncHandler simplifica o código, retirando a necessidade de vários blocos try/catch e gerencia os erros de maneira que permita que o Express trate-os de maneira centralizada.Hoje com algum tempo de atuação no mercado, eu já tento sempre implantar melhorias que aumentem a qualidade de código, facilite sua manutenção e torne escalável e fácil de entender, mesmo em projetos de estudo. E eu não faço isso depois de “entregar a atividade”. Eu faço durante a construção do código, assim que pego a ideia do que precisa ser feito, analiso o que pode melhorar e aplico.O mesmo vale pra quem ainda não tem experiência profissional, mesmo nos estudos, a pessoa começa a desenvolver algumas habilidades que ajudam a sair do goHorseX. É muito importante para o aprendizado ter autonomia e iniciativa ao desenvolver projetos de estudos porque você NUNCA vai aprender aquilo se ficar só copiando o que o instrutor está codando.Tente, aplique melhorias, crie outras features, formule hipóteses, tenha visão crítica para buscar melhorias, quebre sua aplicação, leia os logs e o console, vá tratando com a vida real. Na vida real, um código que já sai funcionando bonitinho de cara com tudo bem entregue é coisa rara. E se você se deparar com algum assim, sugiro desconfiar.Você só vai desenvolver novas habilidades se você se expor a novos problemas a serem resolvidos. E copiar código de alguém definitivamente não é um problema.Abraço!"
  },
  
  {
    "title": "Minhas impressões sobre ingressar na área de TI - Parte III",
    "url": "/posts/start-in-IT-pt-III/",
    "categories": "Carreira, Programação",
    "tags": "carreira, programação, juninho, inglês",
    "date": "2024-08-22 09:10:00 -0300",
    





    
    "snippet": "Nas últimas postagens, abordei sobre aspectos técnicos e comportamentais que, baseados na minha experiência, achei legal compartilhar para as pessoas interessadas em ingressar na área de TI.Faltou ...",
    "content": "Nas últimas postagens, abordei sobre aspectos técnicos e comportamentais que, baseados na minha experiência, achei legal compartilhar para as pessoas interessadas em ingressar na área de TI.Faltou um ponto importante que merece uma abordagem a parte, o inglês.Hoje em dia com as IAs generativas, tem muita gente abandonando literatura e documentação. O que é um equívoco, pois os materiais técnicos não correm risco de alucinar e não concordam com você quando você tá errado.Muitos materiais de qualidade estão em inglês. E infelizmente, a maioria dos materiais pioneiros ainda são produzidos lá fora primeiro. A maioria das empresas que você vai trabalhar, mesmo as brasileiras, por padrão utilizam o inglês para escrever códigos, funções, nomes de variáveis, documentação etc. Então é de suma importância ter conhecimento sobre o idioma pra poder se inserir mais rápido em qualquer contexto.E um outro ponto importante é que saber inglês abre novos portais na sua vida pessoa e profissional.Recentemente eu iniciei minha carreira em uma empresa do exterior trabalhando remoto do Brasil. Eu nunca fiz curso de inglês ou intercâmbio porque quando era novo minha mãe tinha mal dinheiro pra pagar minha escola e depois de velho, difícil você tirar 6 meses sabáticos pra intercâmbio quando tem contas a pagar. Então aprendi como qualquer jovem sem recurso: fiz o que dava. Aprendi na curiosidade de entender os jogos, me expuso voluntariamente a leituras em inglês, assistindo filmes e séries legendadas, aos poucos tirando as legendas. Isso tudo me ajudou muito na leitura, escrita e compreensão.Mas a conversação é um caso a parte. Eu tinha total condições de compreender qualquer coisa dita a mim. Mas tinha uma grande insegurança ao falar. Me juntei a alguns grupos de discussões de negócios em redes sociais há uns anos atrás pra poder trocar ideia sobre vários assuntos “business” e poder destravar. Mesmo assim, não me sentia “fluente” ao ponto de fazer uma entrevista. Mas foi ao fazer minha primeira entrevista em inglês que vi que eu sabia mais do que imaginava. Conseguir fazer uma entrevista técnica com live coding, tudo em inglês foi algo que quebrou as minhas resistências.Acredito que muitas pessoas passam pelo mesmo problema: a falta de confiança. E a melhor maneira é se expor. E gringo julga menos sotaque e pronúncia do que brasileiro. Não leve em consideração se você já fez algum processo seletivo no BR e julgaram você mal pelo seu sotaque ou algo do tipo, a galera aqui é chata pra caralho com isso. Querem só nível 10 na escala Geller do meu amigo Leonardo Marconi.Portanto, se exponha, fale inglês com estrangeiros, vai aprendendo, errando, melhorando, estudando. Não esqueça da leitura, você constrói um vocabulário melhor quanto mais você lê. Não adianta falar bem se só sabe falar bosta.Se alguém estiver lendo isso e quiser dar alguma sugestão sobre assuntos pra quem quer entrar em TI, só entrar em contato.Espero ter ajudado!Abraço!"
  },
  
  {
    "title": "Minhas impressões sobre ingressar na área de TI - Parte II",
    "url": "/posts/start-in-IT-pt-II/",
    "categories": "Carreira, Programação",
    "tags": "carreira, programação, juninho",
    "date": "2024-08-20 02:10:00 -0300",
    





    
    "snippet": "Eu não sou especialista em nada, tudo o que eu falo é baseado na minha experiência, não quero ser influencer nem monetizar isso. Vou tentar condensar um pouco o meu caminho pra conseguir iniciar em...",
    "content": "Eu não sou especialista em nada, tudo o que eu falo é baseado na minha experiência, não quero ser influencer nem monetizar isso. Vou tentar condensar um pouco o meu caminho pra conseguir iniciar em TI sem me ater muito a sacrifícios pessoais, porque isso cada um vai viver os seus.Acredito que a primeira coisa é pesquisar sobre carreiras em TI, back, front, devops, cybersec, dados etc e entender o que quer fazer. Muito ruim você tentar iniciar uma coisa sem ter noção de onde quer chegar. Eu demorei cerca de 8 meses de estudos pulando de galho em galho, seguindo hypes e papo de vendedor de curso.Na parte de estudos, é muito importante pegar noções básicas de algoritmos e estruturas de dados antes de qualquer linguagem ou framework e entender se programar é pra você mesmo. Muita gente começa empolgada com a ideia de trabalhar remoto, trabalhar em casa e acha que a rotina é tranquila, mas é uma carreira que exige bastante, em alguns momentos você vai ter uma carga de trabalho puxada e todos os dias você acorda obsoleto se não se atualizar. Se não gostar, no longo prazo pode ser uma grande frustração.Sobre comunidade, eu tenho uma opinião não muito agradável sobre a bolha dev, então se cerce de poucos e bons. No começo ter alguém que já tá na área que possa te dar uma orientação pode ajudar muito a não perder tempo estudando coisas sem necessidade e até mesmo com uma indicação. E ao se posicionar em redes sociais, é importante ter esse pensamento. Tem pessoas muito boas tecnicamentes e como humanos por aí, construir boas conexões com essas pessoas vai ajudar muito.Não se empolga com hype de rede social, não vai atrás de influencer e foca no que dá empregabilidade. Que depois que você tiver na prática, sempre vai ter que estar aberto para aprender novas tecnologias. Você só vai escolher 100% das tecnologias que vai trabalhar se um dia você for lidar com um projeto só seu. Enquanto for trabalhar para os outros, vai precisar ser flexível.Espero que tenha sido útil.Abraço!"
  },
  
  {
    "title": "Minhas impressões sobre ingressar na área de TI - Parte I",
    "url": "/posts/start-in-IT-pt-I/",
    "categories": "Carreira, Programação",
    "tags": "carreira, programação, juninho",
    "date": "2024-08-19 15:45:00 -0300",
    





    
    "snippet": "Algumas pessoas já vieram conversar comigo sobre iniciar em TI e transição de carreira. Muito pela experiência que tive fazendo uma mudança de carreira há alguns anos atrás.Tem algumas perguntas fr...",
    "content": "Algumas pessoas já vieram conversar comigo sobre iniciar em TI e transição de carreira. Muito pela experiência que tive fazendo uma mudança de carreira há alguns anos atrás.Tem algumas perguntas frequentes que costumam fazer e eu vou deixar aqui as minhas opiniões baseadas na minha vivência. Caso você tenha outras sugestões, pode deixar aqui nos comentários que certamente vai ajudar alguém.❓ Devo fazer uma faculdade de TI?➡ Eu recomendo. Apesar de não ser fundamental para muitas vagas, a vivência acadêmica faz diferença. Mas não considere isso um diferencial. Porém, muitas vagas pedem, então é bom ficar ligado. E considerando que estágio hoje é a porta de entrada mais fácil do que começar como Júnior tendo zero experiência, é um caminho a se considerar.❓Com qual linguagem de programação eu deveria começar?➡ Qualquer coisa pouco complexa pra não assustar de início e poder pegar o básico (Python ou JS), e depois passar para outras de acordo com os planos seguintes. O que importa é se familiarizar com lógica de programação, ter contato com estruturas de controle, algoritmos e estrutura de dados. Depois é mais fácil você se adaptar a mudanças de linguagens;❓ Todo programador deveria saber C?➡ Não. Eu não sei C a fundo. Mas se precisar eu aprendo. E é essa abertura pra aprender que devemos ter uma vez que pegamos bem as bases.❓ Qual deveria ser a minha segunda linguagem?➡ Sempre bom ter noções de JavaScript para entender o front-end e alguma outra de back-end (Java, Python, C#). Mas recomendo também pegar banco de dados, principalmente SQL por ser amplamente utilizada e ter muitos detalhes, alguns bem pequenos, que fazem grande diferença. Não a nível DBA, mas entender as interações de uma aplicação com um banco de dados, como acontece em um CRUD por exemplo.❓ Não tenho como pagar uma graduação e nem curso, e agora?➡ Tem a Universidade Brasileira Livre no github que tem um curso de ciência da computação, por assim dizer, na faixa. Além de vários cursos gratuitos por aí como do Gustavo Guanabara no Curso em Vídeo e vindo pra algo mais nichado da minha rede o Jose Santos que tem um canal no youtube com um curso completão de programação com C#. Mas não é sobre C#, independente da linguagem, ele aborda conceitos fundamentais de programação.❓ Preciso ter um setup de ultima geração para estudar programação?➡ Eu comecei com um notebook meia boca. Setup cheio de luz de natal é luxo. Vale a pena investir em coisas melhores quando você tiver dinheiro pra isso.❓ Como saber a trilha que devo seguir para a tecnologia que escolhi?➡ Tem um site muito bom chamado Roadmap contendo trilhas intuitivas de diversas tecnologias. Mas você também pode pesquisar no Google, por exemplo: “roadmap backend”.❓ O que fazer diante de tantas informações na internet?➡ Aprender a pesquisar e corroborar as informações é sempre a melhor escolha. Infelizmente, só a experiência nos ensina a filtrar muitas coisas que vemos por aí. E sair um pouco de redes sociais ajuda.❓ Tem alguma dica para quem está no inicio?➡ Paciência, disciplina pra estudar, não pular as etapas das bases de algoritmos, estruturas de dados, git e coisas do tipo, não cair em hype de rede social e buscar se conectar com pessoas experientes dispostas a ajudar. Ter gente boa aconselhando faz muita diferença e eu não tive isso no meu início.Abraços!"
  },
  
  {
    "title": "Papos abstratos",
    "url": "/posts/abstract-talks/",
    "categories": "Programação, Orientação a objetos",
    "tags": "programação, poo, abstração",
    "date": "2024-08-18 20:43:00 -0300",
    





    
    "snippet": "Abstração é um termo bastante comum quando falamos de programação. Mas, o que exatamente isso significa? Pintura?Para entender melhor, vamos explorar o conceito dentro do contexto da Programação Or...",
    "content": "Abstração é um termo bastante comum quando falamos de programação. Mas, o que exatamente isso significa? Pintura?Para entender melhor, vamos explorar o conceito dentro do contexto da Programação Orientada a Objetos (POO), que utiliza classes e objetos.Imagine que você vai a um restaurante. No restaurante, há uma série de elementos com os quais você interage para conseguir sua refeição. Esses elementos vão desde objetos (como mesas e cadeiras) até ações realizadas por você ou pelos funcionários do restaurante.No conceito de POO, uma classe é uma abstração que define as propriedades e comportamentos de um tipo de objeto. Por exemplo, a classe Restaurante pode abstrair características como o tipo de comida que serve, o grau de avaliação, a quantidade de lugares, entre outros. Além disso, a classe pode definir comportamentos como preparar comida, fazer uma entrega e receber clientes.A ideia principal da abstração é simplificar sistemas complexos, focando nas partes essenciais e ocultando os detalhes mais complicados e desnecessários. Isso permite que o desenvolvedor trabalhe com sistemas complexos criando representações mais simples e gerais dos objetos.No caso do restaurante, você não precisa saber o nome do cozinheiro, como o prédio foi construído, ou onde os ingredientes foram comprados. O que você precisa saber é o que o restaurante faz: recebe pessoas, prepara e serve comida, e também faz entregas. Estes são os métodos da classe. E tem a estrutura para isso, que são seus atributos.Essa abordagem ajuda a gerenciar a complexidade e permite uma visão mais clara e objetiva do sistema."
  },
  
  {
    "title": "HTTP e seus métodos",
    "url": "/posts/http-methods/",
    "categories": "Internet, HTTP",
    "tags": "internet, http, basics",
    "date": "2024-08-16 21:04:00 -0300",
    





    
    "snippet": "Seja você frontend ou backend, precisa saber como funciona a web.Nas imagem abaixo, você pode ver que no início do roadmap de back-end, é um dos itens básicos.Um erro que muito dev iniciante comete...",
    "content": "Seja você frontend ou backend, precisa saber como funciona a web.Nas imagem abaixo, você pode ver que no início do roadmap de back-end, é um dos itens básicos.Um erro que muito dev iniciante comete é já sair escrevendo linhas códigos sem saber como tudo funciona por baixo dos panos.E uma das bases é o HTTP. Como eu falei no último post, o protocolo HTTP é utilizado para comunicação cliente-servidor para troca de informação através de requisições.Os métodos mais utilizados para realizar essas trocas são:1 - GET: utilizado pra solicitar dados do servidor,2 - POST: utilizado para submeter uma inclusão de uma entidade a um conteúdo específico do lado do servidor;3 - PUT: Utilizado para substituir os dados existentes de um recurso específico;4 - DELETE: Remove um recurso específico.Importante ressaltar que esses métodos devem ser levado em conta na construção de uma API. Utilizar um GET pra fazer uma alteração numa base de dados do lado do servidor, por exemplo, não é adequado por ser possível visualizar dados sensíveis via URL da requisição.E pra quem ficou curioso sobre os roadmaps, você pode conferir a ferramenta aqui.Abraços!"
  },
  
  {
    "title": "HTTP basicão",
    "url": "/posts/http-basics/",
    "categories": "Internet, HTTP",
    "tags": "internet, http, basics",
    "date": "2024-08-15 21:04:00 -0300",
    





    
    "snippet": "Eu sei que você que adora fazer projeto dizendo que tá consumindo API sem nem saber como aquilo funciona.Você sabe do que se trata HTTP?Não se culpe por sair codando sem saber que raios faz HTTP, e...",
    "content": "Eu sei que você que adora fazer projeto dizendo que tá consumindo API sem nem saber como aquilo funciona.Você sabe do que se trata HTTP?Não se culpe por sair codando sem saber que raios faz HTTP, eu era assim. Muitos desses cursos não incentivam o conhecimento de base da web.Hypertext Transfer Protocol (HTTP) é um protocolo (sistema de regras que define como os dados vão ser trafegados) que permite que o usuário obtenha recursos, como por exemplo um documento HTML da vida.É um protocolo cliente-servidor, parte do destinatário a requisição (request) e o servidor atende essa requisição retornando uma resposta (response).Exemplo bem simples pra ficar mais claro: você envia um post aqui no LinkedIn, isso é uma requisição HTTP que envia uma solicitação de inclusão de um dado novo para o servidor, que por sua vez executa a requisição e retorna a resposta.Essa resposta vem com um status, que sinaliza se a requisição foi bem sucedida ou se algum erro aconteceu durante sua execução.Existem métodos diferentes para cada tipo de requisição. Mas isso fica pra um próximo post.Aqui eu deixo uma maneira que ilustra bem legal os status de resposta de requisições HTTP.Abraços!"
  }
  
]

